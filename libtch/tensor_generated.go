/* THIS FILE IS AUTOMATICALLY GENERATED, DO NOT EDIT BY HAND! */

package libtch


func internal_and_Scalar(self Tensor, other Scalar) Tensor {
    f_internal_and_(other)
}

func internal_and_1(self Tensor, other Tensor) Tensor {
    f_internal_and_1(other)
}

func internal_iand_Scalar(self Tensor, other Scalar) Tensor {
    f_internal_iand_(other)
}

func internal_iand_1(self Tensor, other Tensor) Tensor {
    f_internal_iand_1(other)
}

func internal_ilshift_Scalar(self Tensor, other Scalar) Tensor {
    f_internal_ilshift_(other)
}

func internal_ilshift_1(self Tensor, other Tensor) Tensor {
    f_internal_ilshift_1(other)
}

func internal_ior_Scalar(self Tensor, other Scalar) Tensor {
    f_internal_ior_(other)
}

func internal_ior_1(self Tensor, other Tensor) Tensor {
    f_internal_ior_1(other)
}

func internal_irshift_Scalar(self Tensor, other Scalar) Tensor {
    f_internal_irshift_(other)
}

func internal_irshift_1(self Tensor, other Tensor) Tensor {
    f_internal_irshift_1(other)
}

func internal_ixor_Scalar(self Tensor, other Scalar) Tensor {
    f_internal_ixor_(other)
}

func internal_ixor_1(self Tensor, other Tensor) Tensor {
    f_internal_ixor_1(other)
}

func internal_lshift_Scalar(self Tensor, other Scalar) Tensor {
    f_internal_lshift_(other)
}

func internal_lshift_1(self Tensor, other Tensor) Tensor {
    f_internal_lshift_1(other)
}

func internal_or_Scalar(self Tensor, other Scalar) Tensor {
    f_internal_or_(other)
}

func internal_or_1(self Tensor, other Tensor) Tensor {
    f_internal_or_1(other)
}

func internal_rshift_Scalar(self Tensor, other Scalar) Tensor {
    f_internal_rshift_(other)
}

func internal_rshift_1(self Tensor, other Tensor) Tensor {
    f_internal_rshift_1(other)
}

func internal_xor_Scalar(self Tensor, other Scalar) Tensor {
    f_internal_xor_(other)
}

func internal_xor_1(self Tensor, other Tensor) Tensor {
    f_internal_xor_1(other)
}

func internal_adaptive_avg_pool2d(self Tensor, output_size []int64) Tensor {
    f_internal_adaptive_avg_pool2d(output_size)
}

func internal_adaptive_avg_pool2d_backward(self Tensor, grad_output Tensor) Tensor {
    f_internal_adaptive_avg_pool2d_backward(grad_output)
}

func internal_addr(self Tensor, vec1 Tensor, vec2 Tensor) Tensor {
    f_internal_addr(vec1, vec2)
}

func internal_addr_(self Tensor, vec1 Tensor, vec2 Tensor) Tensor {
    f_internal_addr_(vec1, vec2)
}

func internal_addr_out(self Tensor, out Tensor, vec1 Tensor, vec2 Tensor) Tensor {
    f_internal_addr_out(out, vec1, vec2)
}

func internal_amp_update_scale(self Tensor, growth_tracker Tensor, current_scale Tensor, found_inf Tensor, scale_growth_factor float64, scale_backoff_factor float64, growth_interval int64) Tensor {
    f_internal_amp_update_scale(growth_tracker, current_scale, found_inf, scale_growth_factor, scale_backoff_factor, growth_interval)
}

func internal_baddbmm_mkl_(self Tensor, batch1 Tensor, batch2 Tensor) Tensor {
    f_internal_baddbmm_mkl_(batch1, batch2)
}

func internal_cast_byte(self Tensor, non_blocking bool) Tensor {
    f_internal_cast_byte(non_blocking)
}

func internal_cast_char(self Tensor, non_blocking bool) Tensor {
    f_internal_cast_char(non_blocking)
}

func internal_cast_double(self Tensor, non_blocking bool) Tensor {
    f_internal_cast_double(non_blocking)
}

func internal_cast_float(self Tensor, non_blocking bool) Tensor {
    f_internal_cast_float(non_blocking)
}

func internal_cast_half(self Tensor, non_blocking bool) Tensor {
    f_internal_cast_half(non_blocking)
}

func internal_cast_int(self Tensor, non_blocking bool) Tensor {
    f_internal_cast_int(non_blocking)
}

func internal_cast_long(self Tensor, non_blocking bool) Tensor {
    f_internal_cast_long(non_blocking)
}

func internal_cast_short(self Tensor, non_blocking bool) Tensor {
    f_internal_cast_short(non_blocking)
}

func internal_catTensor(self Tensor, tensors []Tensor, dim int64) Tensor {
    f_internal_cat(tensors, dim)
}

func internal_cat_outTensor(self Tensor, out Tensor, tensors []Tensor, dim int64) Tensor {
    f_internal_cat_out(out, tensors, dim)
}

func internal_cdist_backward(self Tensor, grad Tensor, x1 Tensor, x2 Tensor, p float64, cdist Tensor) Tensor {
    f_internal_cdist_backward(grad, x1, x2, p, cdist)
}

func internal_cholesky_helper(self Tensor, upper bool) Tensor {
    f_internal_cholesky_helper(upper)
}

func internal_cholesky_solve_helper(self Tensor, a Tensor, upper bool) Tensor {
    f_internal_cholesky_solve_helper(a, upper)
}

func internal_coalesced_(self Tensor, coalesced bool) Tensor {
    f_internal_coalesced_(coalesced)
}

func internal_convolutionTensor(self Tensor, input Tensor, weight Tensor, bias TensorOption, stride []int64, padding []int64, dilation []int64, transposed bool, output_padding []int64, groups int64, benchmark bool, deterministic bool, cudnn_enabled bool) Tensor {
    f_internal_convolution(input, weight, bias, stride, padding, dilation, transposed, output_padding, groups, benchmark, deterministic, cudnn_enabled)
}

func internal_convolution_nogroupTensor(self Tensor, input Tensor, weight Tensor, bias TensorOption, stride []int64, padding []int64, dilation []int64, transposed bool, output_padding []int64) Tensor {
    f_internal_convolution_nogroup(input, weight, bias, stride, padding, dilation, transposed, output_padding)
}

func internal_copy_from(self Tensor, dst Tensor, non_blocking bool) Tensor {
    f_internal_copy_from(dst, non_blocking)
}

func internal_ctc_loss(self Tensor, log_probs Tensor, targets Tensor, input_lengths []int64, target_lengths []int64, blank int64, zero_infinity bool) (Tensor, Tensor) {
    f_internal_ctc_loss(log_probs, targets, input_lengths, target_lengths, blank, zero_infinity)
}

func internal_ctc_loss_backward(self Tensor, grad Tensor, log_probs Tensor, targets Tensor, input_lengths []int64, target_lengths []int64, neg_log_likelihood Tensor, log_alpha Tensor, blank int64, zero_infinity bool) Tensor {
    f_internal_ctc_loss_backward(grad, log_probs, targets, input_lengths, target_lengths, neg_log_likelihood, log_alpha, blank, zero_infinity)
}

func internal_cudnn_ctc_loss(self Tensor, log_probs Tensor, targets Tensor, input_lengths []int64, target_lengths []int64, blank int64, deterministic bool, zero_infinity bool) (Tensor, Tensor) {
    f_internal_cudnn_ctc_loss(log_probs, targets, input_lengths, target_lengths, blank, deterministic, zero_infinity)
}

func internal_cudnn_init_dropout_state(self Tensor, dropout float64, train bool, dropout_seed int64, options (Kind, Device)) Tensor {
    f_internal_cudnn_init_dropout_state(dropout, train, dropout_seed, options)
}

func internal_cudnn_rnnTensor(self Tensor, input Tensor, weight []Tensor, weight_stride0 int64, weight_buf TensorOption, hx Tensor, cx TensorOption, mode int64, hidden_size int64, num_layers int64, batch_first bool, dropout float64, train bool, bidirectional bool, batch_sizes []int64, dropout_state TensorOption) (Tensor, Tensor, Tensor, Tensor, Tensor) {
    f_internal_cudnn_rnn(input, weight, weight_stride0, weight_buf, hx, cx, mode, hidden_size, num_layers, batch_first, dropout, train, bidirectional, batch_sizes, dropout_state)
}

func internal_cudnn_rnn_flatten_weightTensor(self Tensor, weight_arr []Tensor, weight_stride0 int64, input_size int64, mode int64, hidden_size int64, num_layers int64, batch_first bool, bidirectional bool) Tensor {
    f_internal_cudnn_rnn_flatten_weight(weight_arr, weight_stride0, input_size, mode, hidden_size, num_layers, batch_first, bidirectional)
}

func internal_cumprod(self Tensor, dim int64) Tensor {
    f_internal_cumprod(dim)
}

func internal_cumprod_out(self Tensor, out Tensor, dim int64) Tensor {
    f_internal_cumprod_out(out, dim)
}

func internal_cumsum(self Tensor, dim int64) Tensor {
    f_internal_cumsum(dim)
}

func internal_cumsum_out(self Tensor, out Tensor, dim int64) Tensor {
    f_internal_cumsum_out(out, dim)
}

func internal_dim_arange(self Tensor, like Tensor, dim int64) Tensor {
    f_internal_dim_arange(like, dim)
}

func internal_dirichlet_grad(self Tensor, x Tensor, alpha Tensor, total Tensor) Tensor {
    f_internal_dirichlet_grad(x, alpha, total)
}

func internal_embedding_bagTensor(self Tensor, weight Tensor, indices Tensor, offsets Tensor, scale_grad_by_freq bool, mode int64, sparse bool, per_sample_weights TensorOption, include_last_offset bool) (Tensor, Tensor, Tensor, Tensor) {
    f_internal_embedding_bag(weight, indices, offsets, scale_grad_by_freq, mode, sparse, per_sample_weights, include_last_offset)
}

func internal_embedding_bag_backwardTensor(self Tensor, grad Tensor, indices Tensor, offsets Tensor, offset2bag Tensor, bag_size Tensor, maximum_indices Tensor, num_weights int64, scale_grad_by_freq bool, mode int64, sparse bool, per_sample_weights TensorOption) Tensor {
    f_internal_embedding_bag_backward(grad, indices, offsets, offset2bag, bag_size, maximum_indices, num_weights, scale_grad_by_freq, mode, sparse, per_sample_weights)
}

func internal_embedding_bag_dense_backwardTensor(self Tensor, grad Tensor, indices Tensor, offsets Tensor, offset2bag Tensor, bag_size Tensor, maximum_indices Tensor, num_weights int64, scale_grad_by_freq bool, mode int64, per_sample_weights TensorOption) Tensor {
    f_internal_embedding_bag_dense_backward(grad, indices, offsets, offset2bag, bag_size, maximum_indices, num_weights, scale_grad_by_freq, mode, per_sample_weights)
}

func internal_embedding_bag_per_sample_weights_backward(self Tensor, grad Tensor, weight Tensor, indices Tensor, offsets Tensor, offset2bag Tensor, mode int64) Tensor {
    f_internal_embedding_bag_per_sample_weights_backward(grad, weight, indices, offsets, offset2bag, mode)
}

func internal_embedding_bag_sparse_backwardTensor(self Tensor, grad Tensor, indices Tensor, offsets Tensor, offset2bag Tensor, bag_size Tensor, num_weights int64, scale_grad_by_freq bool, mode int64, per_sample_weights TensorOption) Tensor {
    f_internal_embedding_bag_sparse_backward(grad, indices, offsets, offset2bag, bag_size, num_weights, scale_grad_by_freq, mode, per_sample_weights)
}

func internal_empty_affine_quantized(self Tensor, size []int64, options (Kind, Device), scale float64, zero_point int64) Tensor {
    f_internal_empty_affine_quantized(size, options, scale, zero_point)
}

func internal_empty_per_channel_affine_quantized(self Tensor, size []int64, scales Tensor, zero_points Tensor, axis int64, options (Kind, Device)) Tensor {
    f_internal_empty_per_channel_affine_quantized(size, scales, zero_points, axis, options)
}

func internal_fft_with_size(self Tensor, signal_ndim int64, complex_input bool, complex_output bool, inverse bool, checked_signal_sizes []int64, normalized bool, onesided bool, output_sizes []int64) Tensor {
    f_internal_fft_with_size(signal_ndim, complex_input, complex_output, inverse, checked_signal_sizes, normalized, onesided, output_sizes)
}

func internal_fused_dropout(self Tensor, p float64) (Tensor, Tensor) {
    f_internal_fused_dropout(p)
}

func internal_gather_sparse_backward(self Tensor, dim int64, index Tensor, grad Tensor) Tensor {
    f_internal_gather_sparse_backward(dim, index, grad)
}

func internal_index_copy_(self Tensor, dim int64, index Tensor, source Tensor) Tensor {
    f_internal_index_copy_(dim, index, source)
}

func internal_index_put_impl_Tensor(self Tensor, indices []Tensor, values Tensor, accumulate bool, unsafe_ bool) Tensor {
    f_internal_index_put_impl_(indices, values, accumulate, unsafe_)
}

func internal_indices(self Tensor, ) Tensor {
    f_internal_indices()
}

func internal_inverse_helper(self Tensor, ) Tensor {
    f_internal_inverse_helper()
}

func internal_log_softmax(self Tensor, dim int64, half_to_float bool) Tensor {
    f_internal_log_softmax(dim, half_to_float)
}

func internal_log_softmax_backward_data(self Tensor, grad_output Tensor, output Tensor, dim int64) Tensor {
    f_internal_log_softmax_backward_data(grad_output, output, dim)
}

func internal_lu_solve_helper(self Tensor, lu_data Tensor, lu_pivots Tensor) Tensor {
    f_internal_lu_solve_helper(lu_data, lu_pivots)
}

func internal_lu_with_info(self Tensor, pivot bool, check_errors bool) (Tensor, Tensor, Tensor) {
    f_internal_lu_with_info(pivot, check_errors)
}

func internal_make_per_channel_quantized_tensor(self Tensor, scale Tensor, zero_point Tensor, axis int64) Tensor {
    f_internal_make_per_channel_quantized_tensor(scale, zero_point, axis)
}

func internal_make_per_tensor_quantized_tensor(self Tensor, scale float64, zero_point int64) Tensor {
    f_internal_make_per_tensor_quantized_tensor(scale, zero_point)
}

func internal_masked_scale(self Tensor, mask Tensor, scale float64) Tensor {
    f_internal_masked_scale(mask, scale)
}

func internal_max(self Tensor, dim int64, keepdim bool) (Tensor, Tensor) {
    f_internal_max(dim, keepdim)
}

func internal_max_out(self Tensor, max Tensor, max_indices Tensor, dim int64, keepdim bool) (Tensor, Tensor) {
    f_internal_max_out(max, max_indices, dim, keepdim)
}

func internal_min(self Tensor, dim int64, keepdim bool) (Tensor, Tensor) {
    f_internal_min(dim, keepdim)
}

func internal_min_out(self Tensor, min Tensor, min_indices Tensor, dim int64, keepdim bool) (Tensor, Tensor) {
    f_internal_min_out(min, min_indices, dim, keepdim)
}

func internal_mkldnn_reshape(self Tensor, shape []int64) Tensor {
    f_internal_mkldnn_reshape(shape)
}

func internal_mkldnn_transpose(self Tensor, dim0 int64, dim1 int64) Tensor {
    f_internal_mkldnn_transpose(dim0, dim1)
}

func internal_mkldnn_transpose_(self Tensor, dim0 int64, dim1 int64) Tensor {
    f_internal_mkldnn_transpose_(dim0, dim1)
}

func internal_mode(self Tensor, dim int64, keepdim bool) (Tensor, Tensor) {
    f_internal_mode(dim, keepdim)
}

func internal_mode_out(self Tensor, values Tensor, indices Tensor, dim int64, keepdim bool) (Tensor, Tensor) {
    f_internal_mode_out(values, indices, dim, keepdim)
}

func internal_multinomial_alias_draw(self Tensor, j Tensor, q Tensor, num_samples int64) Tensor {
    f_internal_multinomial_alias_draw(j, q, num_samples)
}

func internal_multinomial_alias_setup(self Tensor, probs Tensor) (Tensor, Tensor) {
    f_internal_multinomial_alias_setup(probs)
}

func internal_nnpack_spatial_convolutionTensor(self Tensor, input Tensor, weight Tensor, bias TensorOption, padding []int64, stride []int64) Tensor {
    f_internal_nnpack_spatial_convolution(input, weight, bias, padding, stride)
}

func internal_nnpack_spatial_convolution_backward_input(self Tensor, input Tensor, grad_output Tensor, weight Tensor, padding []int64) Tensor {
    f_internal_nnpack_spatial_convolution_backward_input(input, grad_output, weight, padding)
}

func internal_nnpack_spatial_convolution_backward_weight(self Tensor, input Tensor, weightsize []int64, grad_output Tensor, padding []int64) Tensor {
    f_internal_nnpack_spatial_convolution_backward_weight(input, weightsize, grad_output, padding)
}

func internal_pack_padded_sequence(self Tensor, input Tensor, lengths Tensor, batch_first bool) (Tensor, Tensor) {
    f_internal_pack_padded_sequence(input, lengths, batch_first)
}

func internal_pack_padded_sequence_backward(self Tensor, grad Tensor, input_size []int64, batch_sizes Tensor, batch_first bool) Tensor {
    f_internal_pack_padded_sequence_backward(grad, input_size, batch_sizes, batch_first)
}

func internal_pad_packed_sequenceScalar(self Tensor, data Tensor, batch_sizes Tensor, batch_first bool, padding_value Scalar, total_length int64) (Tensor, Tensor) {
    f_internal_pad_packed_sequence(data, batch_sizes, batch_first, padding_value, total_length)
}

func internal_pdist_backward(self Tensor, grad Tensor, p float64, pdist Tensor) Tensor {
    f_internal_pdist_backward(grad, p, pdist)
}

func internal_qr_helper(self Tensor, some bool) (Tensor, Tensor) {
    f_internal_qr_helper(some)
}

func internal_reshape_from_tensor(self Tensor, shape Tensor) Tensor {
    f_internal_reshape_from_tensor(shape)
}

func internal_s_where(self Tensor, condition Tensor, other Tensor) Tensor {
    f_internal_s_where(condition, other)
}

func internal_sample_dirichlet(self Tensor, ) Tensor {
    f_internal_sample_dirichlet()
}

func internal_shape_as_tensor(self Tensor, ) Tensor {
    f_internal_shape_as_tensor()
}

func internal_sobol_engine_draw(self Tensor, quasi Tensor, n int64, sobolstate Tensor, dimension int64, num_generated int64, dtype Kind) (Tensor, Tensor) {
    f_internal_sobol_engine_draw(quasi, n, sobolstate, dimension, num_generated, dtype)
}

func internal_sobol_engine_ff_(self Tensor, n int64, sobolstate Tensor, dimension int64, num_generated int64) Tensor {
    f_internal_sobol_engine_ff_(n, sobolstate, dimension, num_generated)
}

func internal_sobol_engine_initialize_state_(self Tensor, dimension int64) Tensor {
    f_internal_sobol_engine_initialize_state_(dimension)
}

func internal_sobol_engine_scramble_(self Tensor, ltm Tensor, dimension int64) Tensor {
    f_internal_sobol_engine_scramble_(ltm, dimension)
}

func internal_softmax(self Tensor, dim int64, half_to_float bool) Tensor {
    f_internal_softmax(dim, half_to_float)
}

func internal_softmax_backward_data(self Tensor, grad_output Tensor, output Tensor, dim int64) Tensor {
    f_internal_softmax_backward_data(grad_output, output, dim)
}

func internal_solve_helper(self Tensor, a Tensor) (Tensor, Tensor) {
    f_internal_solve_helper(a)
}

func internal_sparse_addmm(self Tensor, sparse Tensor, dense Tensor) Tensor {
    f_internal_sparse_addmm(sparse, dense)
}

func internal_sparse_coo_tensor_unsafe(self Tensor, indices Tensor, values Tensor, size []int64, options (Kind, Device)) Tensor {
    f_internal_sparse_coo_tensor_unsafe(indices, values, size, options)
}

func internal_sparse_coo_tensor_with_dims(self Tensor, sparse_dim int64, dense_dim int64, size []int64, options (Kind, Device)) Tensor {
    f_internal_sparse_coo_tensor_with_dims(sparse_dim, dense_dim, size, options)
}

func internal_sparse_coo_tensor_with_dims_and_tensors(self Tensor, sparse_dim int64, dense_dim int64, size []int64, indices Tensor, values Tensor, options (Kind, Device)) Tensor {
    f_internal_sparse_coo_tensor_with_dims_and_tensors(sparse_dim, dense_dim, size, indices, values, options)
}

func internal_sparse_mm(self Tensor, sparse Tensor, dense Tensor) Tensor {
    f_internal_sparse_mm(sparse, dense)
}

func internal_sparse_sum(self Tensor, ) Tensor {
    f_internal_sparse_sum()
}

func internal_sparse_sum1(self Tensor, dtype Kind) Tensor {
    f_internal_sparse_sum1(dtype)
}

func internal_sparse_sum2(self Tensor, dim []int64) Tensor {
    f_internal_sparse_sum2(dim)
}

func internal_sparse_sum3(self Tensor, dim []int64, dtype Kind) Tensor {
    f_internal_sparse_sum3(dim, dtype)
}

func internal_sparse_sum_backward(self Tensor, grad Tensor, dim []int64) Tensor {
    f_internal_sparse_sum_backward(grad, dim)
}

func internal_standard_gamma(self Tensor, ) Tensor {
    f_internal_standard_gamma()
}

func internal_standard_gamma_grad(self Tensor, output Tensor) Tensor {
    f_internal_standard_gamma_grad(output)
}

func internal_std(self Tensor, unbiased bool) Tensor {
    f_internal_std(unbiased)
}

func internal_svd_helper(self Tensor, some bool, compute_uv bool) (Tensor, Tensor, Tensor) {
    f_internal_svd_helper(some, compute_uv)
}

func internal_symeig_helper(self Tensor, eigenvectors bool, upper bool) (Tensor, Tensor) {
    f_internal_symeig_helper(eigenvectors, upper)
}

func internal_triangular_solve_helper(self Tensor, a Tensor, upper bool, transpose bool, unitriangular bool) (Tensor, Tensor) {
    f_internal_triangular_solve_helper(a, upper, transpose, unitriangular)
}

func internal_trilinear(self Tensor, i1 Tensor, i2 Tensor, i3 Tensor, expand1 []int64, expand2 []int64, expand3 []int64, sumdim []int64, unroll_dim int64) Tensor {
    f_internal_trilinear(i1, i2, i3, expand1, expand2, expand3, sumdim, unroll_dim)
}

func internal_unique(self Tensor, sorted bool, return_inverse bool) (Tensor, Tensor) {
    f_internal_unique(sorted, return_inverse)
}

func internal_unique2(self Tensor, sorted bool, return_inverse bool, return_counts bool) (Tensor, Tensor, Tensor) {
    f_internal_unique2(sorted, return_inverse, return_counts)
}

func internal_unsafe_view(self Tensor, size []int64) Tensor {
    f_internal_unsafe_view(size)
}

func internal_values(self Tensor, ) Tensor {
    f_internal_values()
}

func internal_var(self Tensor, unbiased bool) Tensor {
    f_internal_var(unbiased)
}

func internal_weight_norm(self Tensor, v Tensor, g Tensor, dim int64) Tensor {
    f_internal_weight_norm(v, g, dim)
}

func internal_weight_norm_cuda_interface(self Tensor, v Tensor, g Tensor, dim int64) (Tensor, Tensor) {
    f_internal_weight_norm_cuda_interface(v, g, dim)
}

func internal_weight_norm_cuda_interface_backward(self Tensor, grad_w Tensor, saved_v Tensor, saved_g Tensor, saved_norms Tensor, dim int64) (Tensor, Tensor) {
    f_internal_weight_norm_cuda_interface_backward(grad_w, saved_v, saved_g, saved_norms, dim)
}

func internal_weight_norm_differentiable_backward(self Tensor, grad_w Tensor, saved_v Tensor, saved_g Tensor, saved_norms Tensor, dim int64) (Tensor, Tensor) {
    f_internal_weight_norm_differentiable_backward(grad_w, saved_v, saved_g, saved_norms, dim)
}

func abs(self Tensor, ) Tensor {
    f_abs()
}

func abs_(self Tensor, ) Tensor {
    f_abs_()
}

func abs_out(self Tensor, out Tensor) Tensor {
    f_abs_out(out)
}

func acos(self Tensor, ) Tensor {
    f_acos()
}

func acos_(self Tensor, ) Tensor {
    f_acos_()
}

func acos_out(self Tensor, out Tensor) Tensor {
    f_acos_out(out)
}

func adaptive_avg_pool1d(self Tensor, output_size []int64) Tensor {
    f_adaptive_avg_pool1d(output_size)
}

func adaptive_avg_pool2d(self Tensor, output_size []int64) Tensor {
    f_adaptive_avg_pool2d(output_size)
}

func adaptive_avg_pool2d_out(self Tensor, out Tensor, output_size []int64) Tensor {
    f_adaptive_avg_pool2d_out(out, output_size)
}

func adaptive_avg_pool3d(self Tensor, output_size []int64) Tensor {
    f_adaptive_avg_pool3d(output_size)
}

func adaptive_avg_pool3d_backward(self Tensor, grad_output Tensor) Tensor {
    f_adaptive_avg_pool3d_backward(grad_output)
}

func adaptive_avg_pool3d_backward_out(self Tensor, grad_input Tensor, grad_output Tensor) Tensor {
    f_adaptive_avg_pool3d_backward_out(grad_input, grad_output)
}

func adaptive_avg_pool3d_out(self Tensor, out Tensor, output_size []int64) Tensor {
    f_adaptive_avg_pool3d_out(out, output_size)
}

func adaptive_max_pool1d(self Tensor, output_size []int64) (Tensor, Tensor) {
    f_adaptive_max_pool1d(output_size)
}

func adaptive_max_pool2d(self Tensor, output_size []int64) (Tensor, Tensor) {
    f_adaptive_max_pool2d(output_size)
}

func adaptive_max_pool2d_backward(self Tensor, grad_output Tensor, indices Tensor) Tensor {
    f_adaptive_max_pool2d_backward(grad_output, indices)
}

func adaptive_max_pool2d_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, indices Tensor) Tensor {
    f_adaptive_max_pool2d_backward_out(grad_input, grad_output, indices)
}

func adaptive_max_pool2d_out(self Tensor, out Tensor, indices Tensor, output_size []int64) (Tensor, Tensor) {
    f_adaptive_max_pool2d_out(out, indices, output_size)
}

func adaptive_max_pool3d(self Tensor, output_size []int64) (Tensor, Tensor) {
    f_adaptive_max_pool3d(output_size)
}

func adaptive_max_pool3d_backward(self Tensor, grad_output Tensor, indices Tensor) Tensor {
    f_adaptive_max_pool3d_backward(grad_output, indices)
}

func adaptive_max_pool3d_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, indices Tensor) Tensor {
    f_adaptive_max_pool3d_backward_out(grad_input, grad_output, indices)
}

func adaptive_max_pool3d_out(self Tensor, out Tensor, indices Tensor, output_size []int64) (Tensor, Tensor) {
    f_adaptive_max_pool3d_out(out, indices, output_size)
}

func g_add(self Tensor, other Tensor) Tensor {
    f_add(other)
}

func g_add1Scalar(self Tensor, other Scalar) Tensor {
    f_add1(other)
}

func g_add_(self Tensor, other Tensor) Tensor {
    f_add_(other)
}

func g_add_1Scalar(self Tensor, other Scalar) Tensor {
    f_add_1(other)
}

func add_out(self Tensor, out Tensor, other Tensor) Tensor {
    f_add_out(out, other)
}

func addbmm(self Tensor, batch1 Tensor, batch2 Tensor) Tensor {
    f_addbmm(batch1, batch2)
}

func addbmm_(self Tensor, batch1 Tensor, batch2 Tensor) Tensor {
    f_addbmm_(batch1, batch2)
}

func addbmm_out(self Tensor, out Tensor, batch1 Tensor, batch2 Tensor) Tensor {
    f_addbmm_out(out, batch1, batch2)
}

func addcdiv(self Tensor, tensor1 Tensor, tensor2 Tensor) Tensor {
    f_addcdiv(tensor1, tensor2)
}

func addcdiv_(self Tensor, tensor1 Tensor, tensor2 Tensor) Tensor {
    f_addcdiv_(tensor1, tensor2)
}

func addcdiv_out(self Tensor, out Tensor, tensor1 Tensor, tensor2 Tensor) Tensor {
    f_addcdiv_out(out, tensor1, tensor2)
}

func addcmul(self Tensor, tensor1 Tensor, tensor2 Tensor) Tensor {
    f_addcmul(tensor1, tensor2)
}

func addcmul_(self Tensor, tensor1 Tensor, tensor2 Tensor) Tensor {
    f_addcmul_(tensor1, tensor2)
}

func addcmul_out(self Tensor, out Tensor, tensor1 Tensor, tensor2 Tensor) Tensor {
    f_addcmul_out(out, tensor1, tensor2)
}

func addmm(self Tensor, mat1 Tensor, mat2 Tensor) Tensor {
    f_addmm(mat1, mat2)
}

func addmm_(self Tensor, mat1 Tensor, mat2 Tensor) Tensor {
    f_addmm_(mat1, mat2)
}

func addmm_out(self Tensor, out Tensor, mat1 Tensor, mat2 Tensor) Tensor {
    f_addmm_out(out, mat1, mat2)
}

func addmv(self Tensor, mat Tensor, vec Tensor) Tensor {
    f_addmv(mat, vec)
}

func addmv_(self Tensor, mat Tensor, vec Tensor) Tensor {
    f_addmv_(mat, vec)
}

func addmv_out(self Tensor, out Tensor, mat Tensor, vec Tensor) Tensor {
    f_addmv_out(out, mat, vec)
}

func addr(self Tensor, vec1 Tensor, vec2 Tensor) Tensor {
    f_addr(vec1, vec2)
}

func addr_(self Tensor, vec1 Tensor, vec2 Tensor) Tensor {
    f_addr_(vec1, vec2)
}

func addr_out(self Tensor, out Tensor, vec1 Tensor, vec2 Tensor) Tensor {
    f_addr_out(out, vec1, vec2)
}

func affine_grid_generator(self Tensor, theta Tensor, size []int64, align_corners bool) Tensor {
    f_affine_grid_generator(theta, size, align_corners)
}

func affine_grid_generator_backward(self Tensor, grad Tensor, size []int64, align_corners bool) Tensor {
    f_affine_grid_generator_backward(grad, size, align_corners)
}

func alias(self Tensor, ) Tensor {
    f_alias()
}

func align_as(self Tensor, other Tensor) Tensor {
    f_align_as(other)
}

func align_tensorsTensor(self Tensor, tensors []Tensor) []Tensor {
    f_align_tensors(tensors)
}

func all(self Tensor, ) Tensor {
    f_all()
}

func all1(self Tensor, dim int64, keepdim bool) Tensor {
    f_all1(dim, keepdim)
}

func all_out(self Tensor, out Tensor, dim int64, keepdim bool) Tensor {
    f_all_out(out, dim, keepdim)
}

func alpha_dropout(self Tensor, input Tensor, p float64, train bool) Tensor {
    f_alpha_dropout(input, p, train)
}

func alpha_dropout_(self Tensor, p float64, train bool) Tensor {
    f_alpha_dropout_(p, train)
}

func angle(self Tensor, ) Tensor {
    f_angle()
}

func angle_out(self Tensor, out Tensor) Tensor {
    f_angle_out(out)
}

func any(self Tensor, ) Tensor {
    f_any()
}

func any1(self Tensor, dim int64, keepdim bool) Tensor {
    f_any1(dim, keepdim)
}

func any_out(self Tensor, out Tensor, dim int64, keepdim bool) Tensor {
    f_any_out(out, dim, keepdim)
}

func arangeScalar(self Tensor, end Scalar, options (Kind, Device)) Tensor {
    f_arange(end, options)
}

func arange1Scalar(self Tensor, start Scalar, end Scalar, options (Kind, Device)) Tensor {
    f_arange1(start, end, options)
}

func arange2Scalar(self Tensor, start Scalar, end Scalar, step Scalar, options (Kind, Device)) Tensor {
    f_arange2(start, end, step, options)
}

func arange_outScalar(self Tensor, out Tensor, end Scalar) Tensor {
    f_arange_out(out, end)
}

func arange_out1Scalar(self Tensor, out Tensor, start Scalar, end Scalar) Tensor {
    f_arange_out1(out, start, end)
}

func argmax(self Tensor, dim int64, keepdim bool) Tensor {
    f_argmax(dim, keepdim)
}

func argmin(self Tensor, dim int64, keepdim bool) Tensor {
    f_argmin(dim, keepdim)
}

func argsort(self Tensor, dim int64, descending bool) Tensor {
    f_argsort(dim, descending)
}

func as_strided(self Tensor, size []int64, stride []int64, storage_offset int64) Tensor {
    f_as_strided(size, stride, storage_offset)
}

func as_strided_(self Tensor, size []int64, stride []int64, storage_offset int64) Tensor {
    f_as_strided_(size, stride, storage_offset)
}

func asin(self Tensor, ) Tensor {
    f_asin()
}

func asin_(self Tensor, ) Tensor {
    f_asin_()
}

func asin_out(self Tensor, out Tensor) Tensor {
    f_asin_out(out)
}

func atan(self Tensor, ) Tensor {
    f_atan()
}

func atan2(self Tensor, other Tensor) Tensor {
    f_atan2(other)
}

func atan2_(self Tensor, other Tensor) Tensor {
    f_atan2_(other)
}

func atan2_out(self Tensor, out Tensor, other Tensor) Tensor {
    f_atan2_out(out, other)
}

func atan_(self Tensor, ) Tensor {
    f_atan_()
}

func atan_out(self Tensor, out Tensor) Tensor {
    f_atan_out(out)
}

func avg_pool1d(self Tensor, kernel_size []int64, stride []int64, padding []int64, ceil_mode bool, count_include_pad bool) Tensor {
    f_avg_pool1d(kernel_size, stride, padding, ceil_mode, count_include_pad)
}

func avg_pool2d(self Tensor, kernel_size []int64, stride []int64, padding []int64, ceil_mode bool, count_include_pad bool, divisor_override int64) Tensor {
    f_avg_pool2d(kernel_size, stride, padding, ceil_mode, count_include_pad, divisor_override)
}

func avg_pool2d_backward(self Tensor, grad_output Tensor, kernel_size []int64, stride []int64, padding []int64, ceil_mode bool, count_include_pad bool, divisor_override int64) Tensor {
    f_avg_pool2d_backward(grad_output, kernel_size, stride, padding, ceil_mode, count_include_pad, divisor_override)
}

func avg_pool2d_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, kernel_size []int64, stride []int64, padding []int64, ceil_mode bool, count_include_pad bool, divisor_override int64) Tensor {
    f_avg_pool2d_backward_out(grad_input, grad_output, kernel_size, stride, padding, ceil_mode, count_include_pad, divisor_override)
}

func avg_pool2d_out(self Tensor, out Tensor, kernel_size []int64, stride []int64, padding []int64, ceil_mode bool, count_include_pad bool, divisor_override int64) Tensor {
    f_avg_pool2d_out(out, kernel_size, stride, padding, ceil_mode, count_include_pad, divisor_override)
}

func avg_pool3d(self Tensor, kernel_size []int64, stride []int64, padding []int64, ceil_mode bool, count_include_pad bool, divisor_override int64) Tensor {
    f_avg_pool3d(kernel_size, stride, padding, ceil_mode, count_include_pad, divisor_override)
}

func avg_pool3d_backward(self Tensor, grad_output Tensor, kernel_size []int64, stride []int64, padding []int64, ceil_mode bool, count_include_pad bool, divisor_override int64) Tensor {
    f_avg_pool3d_backward(grad_output, kernel_size, stride, padding, ceil_mode, count_include_pad, divisor_override)
}

func avg_pool3d_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, kernel_size []int64, stride []int64, padding []int64, ceil_mode bool, count_include_pad bool, divisor_override int64) Tensor {
    f_avg_pool3d_backward_out(grad_input, grad_output, kernel_size, stride, padding, ceil_mode, count_include_pad, divisor_override)
}

func avg_pool3d_out(self Tensor, out Tensor, kernel_size []int64, stride []int64, padding []int64, ceil_mode bool, count_include_pad bool, divisor_override int64) Tensor {
    f_avg_pool3d_out(out, kernel_size, stride, padding, ceil_mode, count_include_pad, divisor_override)
}

func baddbmm(self Tensor, batch1 Tensor, batch2 Tensor) Tensor {
    f_baddbmm(batch1, batch2)
}

func baddbmm_(self Tensor, batch1 Tensor, batch2 Tensor) Tensor {
    f_baddbmm_(batch1, batch2)
}

func baddbmm_out(self Tensor, out Tensor, batch1 Tensor, batch2 Tensor) Tensor {
    f_baddbmm_out(out, batch1, batch2)
}

func bartlett_window(self Tensor, window_length int64, options (Kind, Device)) Tensor {
    f_bartlett_window(window_length, options)
}

func bartlett_window1(self Tensor, window_length int64, periodic bool, options (Kind, Device)) Tensor {
    f_bartlett_window1(window_length, periodic, options)
}

func batch_normTensor(self Tensor, input Tensor, weight TensorOption, bias TensorOption, running_mean TensorOption, running_var TensorOption, training bool, momentum float64, eps float64, cudnn_enabled bool) Tensor {
    f_batch_norm(input, weight, bias, running_mean, running_var, training, momentum, eps, cudnn_enabled)
}

func batch_norm_backward_elemtTensor(self Tensor, grad_out Tensor, input Tensor, mean Tensor, invstd Tensor, weight TensorOption, mean_dy Tensor, mean_dy_xmu Tensor) Tensor {
    f_batch_norm_backward_elemt(grad_out, input, mean, invstd, weight, mean_dy, mean_dy_xmu)
}

func batch_norm_backward_reduceTensor(self Tensor, grad_out Tensor, input Tensor, mean Tensor, invstd Tensor, weight TensorOption, input_g bool, weight_g bool, bias_g bool) (Tensor, Tensor, Tensor, Tensor) {
    f_batch_norm_backward_reduce(grad_out, input, mean, invstd, weight, input_g, weight_g, bias_g)
}

func batch_norm_elemtTensor(self Tensor, input Tensor, weight TensorOption, bias TensorOption, mean Tensor, invstd Tensor, eps float64) Tensor {
    f_batch_norm_elemt(input, weight, bias, mean, invstd, eps)
}

func batch_norm_elemt_outTensor(self Tensor, out Tensor, input Tensor, weight TensorOption, bias TensorOption, mean Tensor, invstd Tensor, eps float64) Tensor {
    f_batch_norm_elemt_out(out, input, weight, bias, mean, invstd, eps)
}

func batch_norm_gather_statsTensor(self Tensor, input Tensor, mean Tensor, invstd Tensor, running_mean TensorOption, running_var TensorOption, momentum float64, eps float64, count int64) (Tensor, Tensor) {
    f_batch_norm_gather_stats(input, mean, invstd, running_mean, running_var, momentum, eps, count)
}

func batch_norm_gather_stats_with_countsTensor(self Tensor, input Tensor, mean Tensor, invstd Tensor, running_mean TensorOption, running_var TensorOption, momentum float64, eps float64, counts []int64) (Tensor, Tensor) {
    f_batch_norm_gather_stats_with_counts(input, mean, invstd, running_mean, running_var, momentum, eps, counts)
}

func batch_norm_stats(self Tensor, input Tensor, eps float64) (Tensor, Tensor) {
    f_batch_norm_stats(input, eps)
}

func batch_norm_update_statsTensor(self Tensor, input Tensor, running_mean TensorOption, running_var TensorOption, momentum float64) (Tensor, Tensor) {
    f_batch_norm_update_stats(input, running_mean, running_var, momentum)
}

func bernoulli(self Tensor, ) Tensor {
    f_bernoulli()
}

func bernoulli1(self Tensor, p float64) Tensor {
    f_bernoulli1(p)
}

func bernoulli_(self Tensor, p Tensor) Tensor {
    f_bernoulli_(p)
}

func bernoulli_1(self Tensor, p float64) Tensor {
    f_bernoulli_1(p)
}

func bernoulli_out(self Tensor, out Tensor) Tensor {
    f_bernoulli_out(out)
}

func bilinearTensor(self Tensor, input1 Tensor, input2 Tensor, weight Tensor, bias TensorOption) Tensor {
    f_bilinear(input1, input2, weight, bias)
}

func binary_cross_entropyTensor(self Tensor, target Tensor, weight TensorOption, reduction int64) Tensor {
    f_binary_cross_entropy(target, weight, reduction)
}

func binary_cross_entropy_backwardTensor(self Tensor, grad_output Tensor, target Tensor, weight TensorOption, reduction int64) Tensor {
    f_binary_cross_entropy_backward(grad_output, target, weight, reduction)
}

func binary_cross_entropy_backward_outTensor(self Tensor, grad_input Tensor, grad_output Tensor, target Tensor, weight TensorOption, reduction int64) Tensor {
    f_binary_cross_entropy_backward_out(grad_input, grad_output, target, weight, reduction)
}

func binary_cross_entropy_outTensor(self Tensor, out Tensor, target Tensor, weight TensorOption, reduction int64) Tensor {
    f_binary_cross_entropy_out(out, target, weight, reduction)
}

func binary_cross_entropy_with_logitsTensor(self Tensor, target Tensor, weight TensorOption, pos_weight TensorOption, reduction int64) Tensor {
    f_binary_cross_entropy_with_logits(target, weight, pos_weight, reduction)
}

func binary_cross_entropy_with_logits_backwardTensor(self Tensor, grad_output Tensor, target Tensor, weight TensorOption, pos_weight TensorOption, reduction int64) Tensor {
    f_binary_cross_entropy_with_logits_backward(grad_output, target, weight, pos_weight, reduction)
}

func bincountTensor(self Tensor, weights TensorOption, minlength int64) Tensor {
    f_bincount(weights, minlength)
}

func bitwise_andScalar(self Tensor, other Scalar) Tensor {
    f_bitwise_and(other)
}

func bitwise_and1(self Tensor, other Tensor) Tensor {
    f_bitwise_and1(other)
}

func bitwise_and_Scalar(self Tensor, other Scalar) Tensor {
    f_bitwise_and_(other)
}

func bitwise_and_1(self Tensor, other Tensor) Tensor {
    f_bitwise_and_1(other)
}

func bitwise_and_out(self Tensor, out Tensor, other Tensor) Tensor {
    f_bitwise_and_out(out, other)
}

func bitwise_and_out1Scalar(self Tensor, out Tensor, other Scalar) Tensor {
    f_bitwise_and_out1(out, other)
}

func bitwise_not(self Tensor, ) Tensor {
    f_bitwise_not()
}

func bitwise_not_(self Tensor, ) Tensor {
    f_bitwise_not_()
}

func bitwise_not_out(self Tensor, out Tensor) Tensor {
    f_bitwise_not_out(out)
}

func bitwise_orScalar(self Tensor, other Scalar) Tensor {
    f_bitwise_or(other)
}

func bitwise_or1(self Tensor, other Tensor) Tensor {
    f_bitwise_or1(other)
}

func bitwise_or_Scalar(self Tensor, other Scalar) Tensor {
    f_bitwise_or_(other)
}

func bitwise_or_1(self Tensor, other Tensor) Tensor {
    f_bitwise_or_1(other)
}

func bitwise_or_out(self Tensor, out Tensor, other Tensor) Tensor {
    f_bitwise_or_out(out, other)
}

func bitwise_or_out1Scalar(self Tensor, out Tensor, other Scalar) Tensor {
    f_bitwise_or_out1(out, other)
}

func bitwise_xorScalar(self Tensor, other Scalar) Tensor {
    f_bitwise_xor(other)
}

func bitwise_xor1(self Tensor, other Tensor) Tensor {
    f_bitwise_xor1(other)
}

func bitwise_xor_Scalar(self Tensor, other Scalar) Tensor {
    f_bitwise_xor_(other)
}

func bitwise_xor_1(self Tensor, other Tensor) Tensor {
    f_bitwise_xor_1(other)
}

func bitwise_xor_out(self Tensor, out Tensor, other Tensor) Tensor {
    f_bitwise_xor_out(out, other)
}

func bitwise_xor_out1Scalar(self Tensor, out Tensor, other Scalar) Tensor {
    f_bitwise_xor_out1(out, other)
}

func blackman_window(self Tensor, window_length int64, options (Kind, Device)) Tensor {
    f_blackman_window(window_length, options)
}

func blackman_window1(self Tensor, window_length int64, periodic bool, options (Kind, Device)) Tensor {
    f_blackman_window1(window_length, periodic, options)
}

func bmm(self Tensor, mat2 Tensor) Tensor {
    f_bmm(mat2)
}

func bmm_out(self Tensor, out Tensor, mat2 Tensor) Tensor {
    f_bmm_out(out, mat2)
}

func broadcast_tensorsTensor(self Tensor, tensors []Tensor) []Tensor {
    f_broadcast_tensors(tensors)
}

func cartesian_prodTensor(self Tensor, tensors []Tensor) Tensor {
    f_cartesian_prod(tensors)
}

func catTensor(self Tensor, tensors []Tensor, dim int64) Tensor {
    f_cat(tensors, dim)
}

func cat_outTensor(self Tensor, out Tensor, tensors []Tensor, dim int64) Tensor {
    f_cat_out(out, tensors, dim)
}

func cauchy_(self Tensor, median float64, sigma float64) Tensor {
    f_cauchy_(median, sigma)
}

func cdist(self Tensor, x1 Tensor, x2 Tensor, p float64, compute_mode int64) Tensor {
    f_cdist(x1, x2, p, compute_mode)
}

func ceil(self Tensor, ) Tensor {
    f_ceil()
}

func ceil_(self Tensor, ) Tensor {
    f_ceil_()
}

func ceil_out(self Tensor, out Tensor) Tensor {
    f_ceil_out(out)
}

func celu(self Tensor, ) Tensor {
    f_celu()
}

func celu_(self Tensor, ) Tensor {
    f_celu_()
}

func chain_matmulTensor(self Tensor, matrices []Tensor) Tensor {
    f_chain_matmul(matrices)
}

func cholesky(self Tensor, upper bool) Tensor {
    f_cholesky(upper)
}

func cholesky_inverse(self Tensor, upper bool) Tensor {
    f_cholesky_inverse(upper)
}

func cholesky_inverse_out(self Tensor, out Tensor, upper bool) Tensor {
    f_cholesky_inverse_out(out, upper)
}

func cholesky_out(self Tensor, out Tensor, upper bool) Tensor {
    f_cholesky_out(out, upper)
}

func cholesky_solve(self Tensor, input2 Tensor, upper bool) Tensor {
    f_cholesky_solve(input2, upper)
}

func cholesky_solve_out(self Tensor, out Tensor, input2 Tensor, upper bool) Tensor {
    f_cholesky_solve_out(out, input2, upper)
}

func chunk(self Tensor, chunks int64, dim int64) []Tensor {
    f_chunk(chunks, dim)
}

func clampScalar(self Tensor, min Scalar, max Scalar) Tensor {
    f_clamp(min, max)
}

func clamp_Scalar(self Tensor, min Scalar, max Scalar) Tensor {
    f_clamp_(min, max)
}

func clamp_maxScalar(self Tensor, max Scalar) Tensor {
    f_clamp_max(max)
}

func clamp_max_Scalar(self Tensor, max Scalar) Tensor {
    f_clamp_max_(max)
}

func clamp_max_outScalar(self Tensor, out Tensor, max Scalar) Tensor {
    f_clamp_max_out(out, max)
}

func clamp_minScalar(self Tensor, min Scalar) Tensor {
    f_clamp_min(min)
}

func clamp_min_Scalar(self Tensor, min Scalar) Tensor {
    f_clamp_min_(min)
}

func clamp_min_outScalar(self Tensor, out Tensor, min Scalar) Tensor {
    f_clamp_min_out(out, min)
}

func clamp_outScalar(self Tensor, out Tensor, min Scalar, max Scalar) Tensor {
    f_clamp_out(out, min, max)
}

func coalesce(self Tensor, ) Tensor {
    f_coalesce()
}

func col2im(self Tensor, output_size []int64, kernel_size []int64, dilation []int64, padding []int64, stride []int64) Tensor {
    f_col2im(output_size, kernel_size, dilation, padding, stride)
}

func col2im_backward(self Tensor, grad_output Tensor, kernel_size []int64, dilation []int64, padding []int64, stride []int64) Tensor {
    f_col2im_backward(grad_output, kernel_size, dilation, padding, stride)
}

func col2im_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, kernel_size []int64, dilation []int64, padding []int64, stride []int64) Tensor {
    f_col2im_backward_out(grad_input, grad_output, kernel_size, dilation, padding, stride)
}

func col2im_out(self Tensor, out Tensor, output_size []int64, kernel_size []int64, dilation []int64, padding []int64, stride []int64) Tensor {
    f_col2im_out(out, output_size, kernel_size, dilation, padding, stride)
}

func combinations(self Tensor, r int64, with_replacement bool) Tensor {
    f_combinations(r, with_replacement)
}

func conj(self Tensor, ) Tensor {
    f_conj()
}

func conj_out(self Tensor, out Tensor) Tensor {
    f_conj_out(out)
}

func constant_pad_nd(self Tensor, pad []int64) Tensor {
    f_constant_pad_nd(pad)
}

func contiguous(self Tensor, ) Tensor {
    f_contiguous()
}

func conv1dTensor(self Tensor, input Tensor, weight Tensor, bias TensorOption, stride []int64, padding []int64, dilation []int64, groups int64) Tensor {
    f_conv1d(input, weight, bias, stride, padding, dilation, groups)
}

func conv2dTensor(self Tensor, input Tensor, weight Tensor, bias TensorOption, stride []int64, padding []int64, dilation []int64, groups int64) Tensor {
    f_conv2d(input, weight, bias, stride, padding, dilation, groups)
}

func conv3dTensor(self Tensor, input Tensor, weight Tensor, bias TensorOption, stride []int64, padding []int64, dilation []int64, groups int64) Tensor {
    f_conv3d(input, weight, bias, stride, padding, dilation, groups)
}

func conv_tbc(self Tensor, weight Tensor, bias Tensor, pad int64) Tensor {
    f_conv_tbc(weight, bias, pad)
}

func conv_tbc_backward(self Tensor, input Tensor, weight Tensor, bias Tensor, pad int64) (Tensor, Tensor, Tensor) {
    f_conv_tbc_backward(input, weight, bias, pad)
}

func conv_transpose1dTensor(self Tensor, input Tensor, weight Tensor, bias TensorOption, stride []int64, padding []int64, output_padding []int64, groups int64, dilation []int64) Tensor {
    f_conv_transpose1d(input, weight, bias, stride, padding, output_padding, groups, dilation)
}

func conv_transpose2dTensor(self Tensor, input Tensor, weight Tensor, bias TensorOption, stride []int64, padding []int64, output_padding []int64, groups int64, dilation []int64) Tensor {
    f_conv_transpose2d(input, weight, bias, stride, padding, output_padding, groups, dilation)
}

func conv_transpose3dTensor(self Tensor, input Tensor, weight Tensor, bias TensorOption, stride []int64, padding []int64, output_padding []int64, groups int64, dilation []int64) Tensor {
    f_conv_transpose3d(input, weight, bias, stride, padding, output_padding, groups, dilation)
}

func convolutionTensor(self Tensor, input Tensor, weight Tensor, bias TensorOption, stride []int64, padding []int64, dilation []int64, transposed bool, output_padding []int64, groups int64) Tensor {
    f_convolution(input, weight, bias, stride, padding, dilation, transposed, output_padding, groups)
}

func convolution_overrideableTensor(self Tensor, input Tensor, weight Tensor, bias TensorOption, stride []int64, padding []int64, dilation []int64, transposed bool, output_padding []int64, groups int64) Tensor {
    f_convolution_overrideable(input, weight, bias, stride, padding, dilation, transposed, output_padding, groups)
}

func copy_sparse_to_sparse_(self Tensor, src Tensor, non_blocking bool) Tensor {
    f_copy_sparse_to_sparse_(src, non_blocking)
}

func cos(self Tensor, ) Tensor {
    f_cos()
}

func cos_(self Tensor, ) Tensor {
    f_cos_()
}

func cos_out(self Tensor, out Tensor) Tensor {
    f_cos_out(out)
}

func cosh(self Tensor, ) Tensor {
    f_cosh()
}

func cosh_(self Tensor, ) Tensor {
    f_cosh_()
}

func cosh_out(self Tensor, out Tensor) Tensor {
    f_cosh_out(out)
}

func cosine_embedding_loss(self Tensor, input1 Tensor, input2 Tensor, target Tensor, margin float64, reduction int64) Tensor {
    f_cosine_embedding_loss(input1, input2, target, margin, reduction)
}

func cosine_similarity(self Tensor, x1 Tensor, x2 Tensor, dim int64, eps float64) Tensor {
    f_cosine_similarity(x1, x2, dim, eps)
}

func cross(self Tensor, other Tensor, dim int64) Tensor {
    f_cross(other, dim)
}

func cross_out(self Tensor, out Tensor, other Tensor, dim int64) Tensor {
    f_cross_out(out, other, dim)
}

func ctc_loss(self Tensor, log_probs Tensor, targets Tensor, input_lengths []int64, target_lengths []int64, blank int64, reduction int64, zero_infinity bool) Tensor {
    f_ctc_loss(log_probs, targets, input_lengths, target_lengths, blank, reduction, zero_infinity)
}

func ctc_loss1(self Tensor, log_probs Tensor, targets Tensor, input_lengths Tensor, target_lengths Tensor, blank int64, reduction int64, zero_infinity bool) Tensor {
    f_ctc_loss1(log_probs, targets, input_lengths, target_lengths, blank, reduction, zero_infinity)
}

func cudnn_affine_grid_generator(self Tensor, theta Tensor, n int64, c int64, h int64, w int64) Tensor {
    f_cudnn_affine_grid_generator(theta, n, c, h, w)
}

func cudnn_affine_grid_generator_backward(self Tensor, grad Tensor, n int64, c int64, h int64, w int64) Tensor {
    f_cudnn_affine_grid_generator_backward(grad, n, c, h, w)
}

func cudnn_batch_normTensor(self Tensor, input Tensor, weight Tensor, bias TensorOption, running_mean TensorOption, running_var TensorOption, training bool, exponential_average_factor float64, epsilon float64) (Tensor, Tensor, Tensor, Tensor) {
    f_cudnn_batch_norm(input, weight, bias, running_mean, running_var, training, exponential_average_factor, epsilon)
}

func cudnn_batch_norm_backwardTensor(self Tensor, input Tensor, grad_output Tensor, weight Tensor, running_mean TensorOption, running_var TensorOption, save_mean TensorOption, save_var TensorOption, epsilon float64, reservespace Tensor) (Tensor, Tensor, Tensor) {
    f_cudnn_batch_norm_backward(input, grad_output, weight, running_mean, running_var, save_mean, save_var, epsilon, reservespace)
}

func cudnn_convolution(self Tensor, weight Tensor, padding []int64, stride []int64, dilation []int64, groups int64, benchmark bool, deterministic bool) Tensor {
    f_cudnn_convolution(weight, padding, stride, dilation, groups, benchmark, deterministic)
}

func cudnn_convolution1Tensor(self Tensor, weight Tensor, bias TensorOption, padding []int64, stride []int64, dilation []int64, groups int64, benchmark bool, deterministic bool) Tensor {
    f_cudnn_convolution1(weight, bias, padding, stride, dilation, groups, benchmark, deterministic)
}

func cudnn_convolution_backward_input(self Tensor, self_size []int64, grad_output Tensor, weight Tensor, padding []int64, stride []int64, dilation []int64, groups int64, benchmark bool, deterministic bool) Tensor {
    f_cudnn_convolution_backward_input(self_size, grad_output, weight, padding, stride, dilation, groups, benchmark, deterministic)
}

func cudnn_convolution_backward_weight(self Tensor, weight_size []int64, grad_output Tensor, padding []int64, stride []int64, dilation []int64, groups int64, benchmark bool, deterministic bool) Tensor {
    f_cudnn_convolution_backward_weight(weight_size, grad_output, padding, stride, dilation, groups, benchmark, deterministic)
}

func cudnn_convolution_transpose(self Tensor, weight Tensor, padding []int64, output_padding []int64, stride []int64, dilation []int64, groups int64, benchmark bool, deterministic bool) Tensor {
    f_cudnn_convolution_transpose(weight, padding, output_padding, stride, dilation, groups, benchmark, deterministic)
}

func cudnn_convolution_transpose1Tensor(self Tensor, weight Tensor, bias TensorOption, padding []int64, output_padding []int64, stride []int64, dilation []int64, groups int64, benchmark bool, deterministic bool) Tensor {
    f_cudnn_convolution_transpose1(weight, bias, padding, output_padding, stride, dilation, groups, benchmark, deterministic)
}

func cudnn_convolution_transpose_backward_input(self Tensor, grad_output Tensor, weight Tensor, padding []int64, stride []int64, dilation []int64, groups int64, benchmark bool, deterministic bool) Tensor {
    f_cudnn_convolution_transpose_backward_input(grad_output, weight, padding, stride, dilation, groups, benchmark, deterministic)
}

func cudnn_convolution_transpose_backward_weight(self Tensor, weight_size []int64, grad_output Tensor, padding []int64, stride []int64, dilation []int64, groups int64, benchmark bool, deterministic bool) Tensor {
    f_cudnn_convolution_transpose_backward_weight(weight_size, grad_output, padding, stride, dilation, groups, benchmark, deterministic)
}

func cudnn_grid_sampler(self Tensor, grid Tensor) Tensor {
    f_cudnn_grid_sampler(grid)
}

func cudnn_grid_sampler_backward(self Tensor, grid Tensor, grad_output Tensor) (Tensor, Tensor) {
    f_cudnn_grid_sampler_backward(grid, grad_output)
}

func cummax(self Tensor, dim int64) (Tensor, Tensor) {
    f_cummax(dim)
}

func cummax_out(self Tensor, values Tensor, indices Tensor, dim int64) (Tensor, Tensor) {
    f_cummax_out(values, indices, dim)
}

func cummin(self Tensor, dim int64) (Tensor, Tensor) {
    f_cummin(dim)
}

func cummin_out(self Tensor, values Tensor, indices Tensor, dim int64) (Tensor, Tensor) {
    f_cummin_out(values, indices, dim)
}

func cumprod(self Tensor, dim int64, dtype Kind) Tensor {
    f_cumprod(dim, dtype)
}

func cumprod_out(self Tensor, out Tensor, dim int64, dtype Kind) Tensor {
    f_cumprod_out(out, dim, dtype)
}

func cumsum(self Tensor, dim int64, dtype Kind) Tensor {
    f_cumsum(dim, dtype)
}

func cumsum_out(self Tensor, out Tensor, dim int64, dtype Kind) Tensor {
    f_cumsum_out(out, dim, dtype)
}

func data(self Tensor, ) Tensor {
    f_data()
}

func dequantize(self Tensor, ) Tensor {
    f_dequantize()
}

func det(self Tensor, ) Tensor {
    f_det()
}

func detach(self Tensor, ) Tensor {
    f_detach()
}

func detach_(self Tensor, ) Tensor {
    f_detach_()
}

func diag(self Tensor, diagonal int64) Tensor {
    f_diag(diagonal)
}

func diag_embed(self Tensor, offset int64, dim1 int64, dim2 int64) Tensor {
    f_diag_embed(offset, dim1, dim2)
}

func diag_out(self Tensor, out Tensor, diagonal int64) Tensor {
    f_diag_out(out, diagonal)
}

func diagflat(self Tensor, offset int64) Tensor {
    f_diagflat(offset)
}

func diagonal(self Tensor, offset int64, dim1 int64, dim2 int64) Tensor {
    f_diagonal(offset, dim1, dim2)
}

func digamma(self Tensor, ) Tensor {
    f_digamma()
}

func digamma_(self Tensor, ) Tensor {
    f_digamma_()
}

func digamma_out(self Tensor, out Tensor) Tensor {
    f_digamma_out(out)
}

func dist(self Tensor, other Tensor) Tensor {
    f_dist(other)
}

func g_div(self Tensor, other Tensor) Tensor {
    f_div(other)
}

func g_div1Scalar(self Tensor, other Scalar) Tensor {
    f_div1(other)
}

func g_div_(self Tensor, other Tensor) Tensor {
    f_div_(other)
}

func g_div_1Scalar(self Tensor, other Scalar) Tensor {
    f_div_1(other)
}

func div_out(self Tensor, out Tensor, other Tensor) Tensor {
    f_div_out(out, other)
}

func dot(self Tensor, tensor Tensor) Tensor {
    f_dot(tensor)
}

func dot_out(self Tensor, out Tensor, tensor Tensor) Tensor {
    f_dot_out(out, tensor)
}

func dropout(self Tensor, input Tensor, p float64, train bool) Tensor {
    f_dropout(input, p, train)
}

func dropout_(self Tensor, p float64, train bool) Tensor {
    f_dropout_(p, train)
}

func eig(self Tensor, eigenvectors bool) (Tensor, Tensor) {
    f_eig(eigenvectors)
}

func eig_out(self Tensor, e Tensor, v Tensor, eigenvectors bool) (Tensor, Tensor) {
    f_eig_out(e, v, eigenvectors)
}

func einsumTensor(self Tensor, equation string, tensors []Tensor) Tensor {
    f_einsum(equation, tensors)
}

func elu(self Tensor, ) Tensor {
    f_elu()
}

func elu_(self Tensor, ) Tensor {
    f_elu_()
}

func elu_backwardScalar(self Tensor, grad_output Tensor, alpha Scalar, scale Scalar, input_scale Scalar, output Tensor) Tensor {
    f_elu_backward(grad_output, alpha, scale, input_scale, output)
}

func elu_backward_outScalar(self Tensor, grad_input Tensor, grad_output Tensor, alpha Scalar, scale Scalar, input_scale Scalar, output Tensor) Tensor {
    f_elu_backward_out(grad_input, grad_output, alpha, scale, input_scale, output)
}

func elu_out(self Tensor, out Tensor) Tensor {
    f_elu_out(out)
}

func embedding(self Tensor, weight Tensor, indices Tensor, padding_idx int64, scale_grad_by_freq bool, sparse bool) Tensor {
    f_embedding(weight, indices, padding_idx, scale_grad_by_freq, sparse)
}

func embedding_backward(self Tensor, grad Tensor, indices Tensor, num_weights int64, padding_idx int64, scale_grad_by_freq bool, sparse bool) Tensor {
    f_embedding_backward(grad, indices, num_weights, padding_idx, scale_grad_by_freq, sparse)
}

func embedding_bagTensor(self Tensor, weight Tensor, indices Tensor, offsets Tensor, scale_grad_by_freq bool, mode int64, sparse bool, per_sample_weights TensorOption, include_last_offset bool) (Tensor, Tensor, Tensor, Tensor) {
    f_embedding_bag(weight, indices, offsets, scale_grad_by_freq, mode, sparse, per_sample_weights, include_last_offset)
}

func embedding_dense_backward(self Tensor, grad_output Tensor, indices Tensor, num_weights int64, padding_idx int64, scale_grad_by_freq bool) Tensor {
    f_embedding_dense_backward(grad_output, indices, num_weights, padding_idx, scale_grad_by_freq)
}

func embedding_renorm_(self Tensor, indices Tensor, max_norm float64, norm_type float64) Tensor {
    f_embedding_renorm_(indices, max_norm, norm_type)
}

func embedding_sparse_backward(self Tensor, grad Tensor, indices Tensor, num_weights int64, padding_idx int64, scale_grad_by_freq bool) Tensor {
    f_embedding_sparse_backward(grad, indices, num_weights, padding_idx, scale_grad_by_freq)
}

func empty(self Tensor, size []int64, options (Kind, Device)) Tensor {
    f_empty(size, options)
}

func empty_like(self Tensor, ) Tensor {
    f_empty_like()
}

func empty_out(self Tensor, out Tensor, size []int64) Tensor {
    f_empty_out(out, size)
}

func empty_strided(self Tensor, size []int64, stride []int64, options (Kind, Device)) Tensor {
    f_empty_strided(size, stride, options)
}

func eqScalar(self Tensor, other Scalar) Tensor {
    f_eq(other)
}

func eq1(self Tensor, other Tensor) Tensor {
    f_eq1(other)
}

func eq_Scalar(self Tensor, other Scalar) Tensor {
    f_eq_(other)
}

func eq_1(self Tensor, other Tensor) Tensor {
    f_eq_1(other)
}

func eq_outScalar(self Tensor, out Tensor, other Scalar) Tensor {
    f_eq_out(out, other)
}

func eq_out1(self Tensor, out Tensor, other Tensor) Tensor {
    f_eq_out1(out, other)
}

func erf(self Tensor, ) Tensor {
    f_erf()
}

func erf_(self Tensor, ) Tensor {
    f_erf_()
}

func erf_out(self Tensor, out Tensor) Tensor {
    f_erf_out(out)
}

func erfc(self Tensor, ) Tensor {
    f_erfc()
}

func erfc_(self Tensor, ) Tensor {
    f_erfc_()
}

func erfc_out(self Tensor, out Tensor) Tensor {
    f_erfc_out(out)
}

func erfinv(self Tensor, ) Tensor {
    f_erfinv()
}

func erfinv_(self Tensor, ) Tensor {
    f_erfinv_()
}

func erfinv_out(self Tensor, out Tensor) Tensor {
    f_erfinv_out(out)
}

func exp(self Tensor, ) Tensor {
    f_exp()
}

func exp_(self Tensor, ) Tensor {
    f_exp_()
}

func exp_out(self Tensor, out Tensor) Tensor {
    f_exp_out(out)
}

func expand(self Tensor, size []int64, implicit bool) Tensor {
    f_expand(size, implicit)
}

func expand_as(self Tensor, other Tensor) Tensor {
    f_expand_as(other)
}

func expm1(self Tensor, ) Tensor {
    f_expm1()
}

func expm1_(self Tensor, ) Tensor {
    f_expm1_()
}

func expm1_out(self Tensor, out Tensor) Tensor {
    f_expm1_out(out)
}

func exponential_(self Tensor, lambd float64) Tensor {
    f_exponential_(lambd)
}

func eye(self Tensor, n int64, options (Kind, Device)) Tensor {
    f_eye(n, options)
}

func eye1(self Tensor, n int64, m int64, options (Kind, Device)) Tensor {
    f_eye1(n, m, options)
}

func eye_out(self Tensor, out Tensor, n int64) Tensor {
    f_eye_out(out, n)
}

func eye_out1(self Tensor, out Tensor, n int64, m int64) Tensor {
    f_eye_out1(out, n, m)
}

func fake_quantize_per_channel_affine(self Tensor, scale Tensor, zero_point Tensor, axis int64, quant_min int64, quant_max int64) Tensor {
    f_fake_quantize_per_channel_affine(scale, zero_point, axis, quant_min, quant_max)
}

func fake_quantize_per_channel_affine_backward(self Tensor, grad Tensor, scale Tensor, zero_point Tensor, axis int64, quant_min int64, quant_max int64) Tensor {
    f_fake_quantize_per_channel_affine_backward(grad, scale, zero_point, axis, quant_min, quant_max)
}

func fake_quantize_per_tensor_affine(self Tensor, scale float64, zero_point int64, quant_min int64, quant_max int64) Tensor {
    f_fake_quantize_per_tensor_affine(scale, zero_point, quant_min, quant_max)
}

func fake_quantize_per_tensor_affine_backward(self Tensor, grad Tensor, scale float64, zero_point int64, quant_min int64, quant_max int64) Tensor {
    f_fake_quantize_per_tensor_affine_backward(grad, scale, zero_point, quant_min, quant_max)
}

func fbgemm_linear_fp16_weight(self Tensor, input Tensor, packed_weight Tensor, bias Tensor) Tensor {
    f_fbgemm_linear_fp16_weight(input, packed_weight, bias)
}

func fbgemm_linear_fp16_weight_fp32_activation(self Tensor, input Tensor, packed_weight Tensor, bias Tensor) Tensor {
    f_fbgemm_linear_fp16_weight_fp32_activation(input, packed_weight, bias)
}

func fbgemm_linear_int8_weightScalar(self Tensor, input Tensor, weight Tensor, packed Tensor, col_offsets Tensor, weight_scale Scalar, weight_zero_point Scalar, bias Tensor) Tensor {
    f_fbgemm_linear_int8_weight(input, weight, packed, col_offsets, weight_scale, weight_zero_point, bias)
}

func fbgemm_linear_int8_weight_fp32_activationScalar(self Tensor, input Tensor, weight Tensor, packed Tensor, col_offsets Tensor, weight_scale Scalar, weight_zero_point Scalar, bias Tensor) Tensor {
    f_fbgemm_linear_int8_weight_fp32_activation(input, weight, packed, col_offsets, weight_scale, weight_zero_point, bias)
}

func fbgemm_pack_gemm_matrix_fp16(self Tensor, input Tensor) Tensor {
    f_fbgemm_pack_gemm_matrix_fp16(input)
}

func fbgemm_pack_quantized_matrix(self Tensor, input Tensor) Tensor {
    f_fbgemm_pack_quantized_matrix(input)
}

func fbgemm_pack_quantized_matrix1(self Tensor, input Tensor, k int64, n int64) Tensor {
    f_fbgemm_pack_quantized_matrix1(input, k, n)
}

func feature_alpha_dropout(self Tensor, input Tensor, p float64, train bool) Tensor {
    f_feature_alpha_dropout(input, p, train)
}

func feature_alpha_dropout_(self Tensor, p float64, train bool) Tensor {
    f_feature_alpha_dropout_(p, train)
}

func feature_dropout(self Tensor, input Tensor, p float64, train bool) Tensor {
    f_feature_dropout(input, p, train)
}

func feature_dropout_(self Tensor, p float64, train bool) Tensor {
    f_feature_dropout_(p, train)
}

func fft(self Tensor, signal_ndim int64, normalized bool) Tensor {
    f_fft(signal_ndim, normalized)
}

func fill_Scalar(self Tensor, value Scalar) Tensor {
    f_fill_(value)
}

func fill_1(self Tensor, value Tensor) Tensor {
    f_fill_1(value)
}

func fill_diagonal_Scalar(self Tensor, fill_value Scalar, wrap bool) Tensor {
    f_fill_diagonal_(fill_value, wrap)
}

func flatten(self Tensor, start_dim int64, end_dim int64) Tensor {
    f_flatten(start_dim, end_dim)
}

func flip(self Tensor, dims []int64) Tensor {
    f_flip(dims)
}

func floor(self Tensor, ) Tensor {
    f_floor()
}

func floor_(self Tensor, ) Tensor {
    f_floor_()
}

func floor_divide(self Tensor, other Tensor) Tensor {
    f_floor_divide(other)
}

func floor_divide1Scalar(self Tensor, other Scalar) Tensor {
    f_floor_divide1(other)
}

func floor_divide_(self Tensor, other Tensor) Tensor {
    f_floor_divide_(other)
}

func floor_divide_1Scalar(self Tensor, other Scalar) Tensor {
    f_floor_divide_1(other)
}

func floor_divide_out(self Tensor, out Tensor, other Tensor) Tensor {
    f_floor_divide_out(out, other)
}

func floor_out(self Tensor, out Tensor) Tensor {
    f_floor_out(out)
}

func fmodScalar(self Tensor, other Scalar) Tensor {
    f_fmod(other)
}

func fmod1(self Tensor, other Tensor) Tensor {
    f_fmod1(other)
}

func fmod_Scalar(self Tensor, other Scalar) Tensor {
    f_fmod_(other)
}

func fmod_1(self Tensor, other Tensor) Tensor {
    f_fmod_1(other)
}

func fmod_outScalar(self Tensor, out Tensor, other Scalar) Tensor {
    f_fmod_out(out, other)
}

func fmod_out1(self Tensor, out Tensor, other Tensor) Tensor {
    f_fmod_out1(out, other)
}

func frac(self Tensor, ) Tensor {
    f_frac()
}

func frac_(self Tensor, ) Tensor {
    f_frac_()
}

func frac_out(self Tensor, out Tensor) Tensor {
    f_frac_out(out)
}

func fractional_max_pool2d(self Tensor, kernel_size []int64, output_size []int64, random_samples Tensor) (Tensor, Tensor) {
    f_fractional_max_pool2d(kernel_size, output_size, random_samples)
}

func fractional_max_pool2d_backward(self Tensor, grad_output Tensor, kernel_size []int64, output_size []int64, indices Tensor) Tensor {
    f_fractional_max_pool2d_backward(grad_output, kernel_size, output_size, indices)
}

func fractional_max_pool2d_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, kernel_size []int64, output_size []int64, indices Tensor) Tensor {
    f_fractional_max_pool2d_backward_out(grad_input, grad_output, kernel_size, output_size, indices)
}

func fractional_max_pool2d_out(self Tensor, output Tensor, indices Tensor, kernel_size []int64, output_size []int64, random_samples Tensor) (Tensor, Tensor) {
    f_fractional_max_pool2d_out(output, indices, kernel_size, output_size, random_samples)
}

func fractional_max_pool3d(self Tensor, kernel_size []int64, output_size []int64, random_samples Tensor) (Tensor, Tensor) {
    f_fractional_max_pool3d(kernel_size, output_size, random_samples)
}

func fractional_max_pool3d_backward(self Tensor, grad_output Tensor, kernel_size []int64, output_size []int64, indices Tensor) Tensor {
    f_fractional_max_pool3d_backward(grad_output, kernel_size, output_size, indices)
}

func fractional_max_pool3d_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, kernel_size []int64, output_size []int64, indices Tensor) Tensor {
    f_fractional_max_pool3d_backward_out(grad_input, grad_output, kernel_size, output_size, indices)
}

func fractional_max_pool3d_out(self Tensor, output Tensor, indices Tensor, kernel_size []int64, output_size []int64, random_samples Tensor) (Tensor, Tensor) {
    f_fractional_max_pool3d_out(output, indices, kernel_size, output_size, random_samples)
}

func frobenius_norm(self Tensor, ) Tensor {
    f_frobenius_norm()
}

func frobenius_norm1(self Tensor, dim []int64, keepdim bool) Tensor {
    f_frobenius_norm1(dim, keepdim)
}

func frobenius_norm_out(self Tensor, out Tensor, dim []int64, keepdim bool) Tensor {
    f_frobenius_norm_out(out, dim, keepdim)
}

func from_file(self Tensor, filename string, shared bool, size int64, options (Kind, Device)) Tensor {
    f_from_file(filename, shared, size, options)
}

func fullScalar(self Tensor, size []int64, fill_value Scalar, options (Kind, Device)) Tensor {
    f_full(size, fill_value, options)
}

func full_likeScalar(self Tensor, fill_value Scalar) Tensor {
    f_full_like(fill_value)
}

func full_outScalar(self Tensor, out Tensor, size []int64, fill_value Scalar) Tensor {
    f_full_out(out, size, fill_value)
}

func gather(self Tensor, dim int64, index Tensor, sparse_grad bool) Tensor {
    f_gather(dim, index, sparse_grad)
}

func gather_out(self Tensor, out Tensor, dim int64, index Tensor, sparse_grad bool) Tensor {
    f_gather_out(out, dim, index, sparse_grad)
}

func geScalar(self Tensor, other Scalar) Tensor {
    f_ge(other)
}

func ge1(self Tensor, other Tensor) Tensor {
    f_ge1(other)
}

func ge_Scalar(self Tensor, other Scalar) Tensor {
    f_ge_(other)
}

func ge_1(self Tensor, other Tensor) Tensor {
    f_ge_1(other)
}

func ge_outScalar(self Tensor, out Tensor, other Scalar) Tensor {
    f_ge_out(out, other)
}

func ge_out1(self Tensor, out Tensor, other Tensor) Tensor {
    f_ge_out1(out, other)
}

func gelu(self Tensor, ) Tensor {
    f_gelu()
}

func gelu_backward(self Tensor, grad Tensor) Tensor {
    f_gelu_backward(grad)
}

func geometric_(self Tensor, p float64) Tensor {
    f_geometric_(p)
}

func geqrf(self Tensor, ) (Tensor, Tensor) {
    f_geqrf()
}

func geqrf_out(self Tensor, a Tensor, tau Tensor) (Tensor, Tensor) {
    f_geqrf_out(a, tau)
}

func ger(self Tensor, vec2 Tensor) Tensor {
    f_ger(vec2)
}

func ger_out(self Tensor, out Tensor, vec2 Tensor) Tensor {
    f_ger_out(out, vec2)
}

func glu(self Tensor, dim int64) Tensor {
    f_glu(dim)
}

func glu_backward(self Tensor, grad_output Tensor, dim int64) Tensor {
    f_glu_backward(grad_output, dim)
}

func glu_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, dim int64) Tensor {
    f_glu_backward_out(grad_input, grad_output, dim)
}

func glu_out(self Tensor, out Tensor, dim int64) Tensor {
    f_glu_out(out, dim)
}

func grad(self Tensor, ) Tensor {
    f_grad()
}

func grid_sampler(self Tensor, input Tensor, grid Tensor, interpolation_mode int64, padding_mode int64, align_corners bool) Tensor {
    f_grid_sampler(input, grid, interpolation_mode, padding_mode, align_corners)
}

func grid_sampler_2d(self Tensor, input Tensor, grid Tensor, interpolation_mode int64, padding_mode int64, align_corners bool) Tensor {
    f_grid_sampler_2d(input, grid, interpolation_mode, padding_mode, align_corners)
}

func grid_sampler_2d_backward(self Tensor, grad_output Tensor, input Tensor, grid Tensor, interpolation_mode int64, padding_mode int64, align_corners bool) (Tensor, Tensor) {
    f_grid_sampler_2d_backward(grad_output, input, grid, interpolation_mode, padding_mode, align_corners)
}

func grid_sampler_3d(self Tensor, input Tensor, grid Tensor, interpolation_mode int64, padding_mode int64, align_corners bool) Tensor {
    f_grid_sampler_3d(input, grid, interpolation_mode, padding_mode, align_corners)
}

func grid_sampler_3d_backward(self Tensor, grad_output Tensor, input Tensor, grid Tensor, interpolation_mode int64, padding_mode int64, align_corners bool) (Tensor, Tensor) {
    f_grid_sampler_3d_backward(grad_output, input, grid, interpolation_mode, padding_mode, align_corners)
}

func group_normTensor(self Tensor, input Tensor, num_groups int64, weight TensorOption, bias TensorOption, eps float64, cudnn_enabled bool) Tensor {
    f_group_norm(input, num_groups, weight, bias, eps, cudnn_enabled)
}

func gruTensor(self Tensor, input Tensor, hx Tensor, params []Tensor, has_biases bool, num_layers int64, dropout float64, train bool, bidirectional bool, batch_first bool) (Tensor, Tensor) {
    f_gru(input, hx, params, has_biases, num_layers, dropout, train, bidirectional, batch_first)
}

func gru1Tensor(self Tensor, data Tensor, batch_sizes Tensor, hx Tensor, params []Tensor, has_biases bool, num_layers int64, dropout float64, train bool, bidirectional bool) (Tensor, Tensor) {
    f_gru1(data, batch_sizes, hx, params, has_biases, num_layers, dropout, train, bidirectional)
}

func gru_cellTensor(self Tensor, input Tensor, hx Tensor, w_ih Tensor, w_hh Tensor, b_ih TensorOption, b_hh TensorOption) Tensor {
    f_gru_cell(input, hx, w_ih, w_hh, b_ih, b_hh)
}

func gtScalar(self Tensor, other Scalar) Tensor {
    f_gt(other)
}

func gt1(self Tensor, other Tensor) Tensor {
    f_gt1(other)
}

func gt_Scalar(self Tensor, other Scalar) Tensor {
    f_gt_(other)
}

func gt_1(self Tensor, other Tensor) Tensor {
    f_gt_1(other)
}

func gt_outScalar(self Tensor, out Tensor, other Scalar) Tensor {
    f_gt_out(out, other)
}

func gt_out1(self Tensor, out Tensor, other Tensor) Tensor {
    f_gt_out1(out, other)
}

func hamming_window(self Tensor, window_length int64, options (Kind, Device)) Tensor {
    f_hamming_window(window_length, options)
}

func hamming_window1(self Tensor, window_length int64, periodic bool, options (Kind, Device)) Tensor {
    f_hamming_window1(window_length, periodic, options)
}

func hamming_window2(self Tensor, window_length int64, periodic bool, alpha float64, options (Kind, Device)) Tensor {
    f_hamming_window2(window_length, periodic, alpha, options)
}

func hamming_window3(self Tensor, window_length int64, periodic bool, alpha float64, beta float64, options (Kind, Device)) Tensor {
    f_hamming_window3(window_length, periodic, alpha, beta, options)
}

func hann_window(self Tensor, window_length int64, options (Kind, Device)) Tensor {
    f_hann_window(window_length, options)
}

func hann_window1(self Tensor, window_length int64, periodic bool, options (Kind, Device)) Tensor {
    f_hann_window1(window_length, periodic, options)
}

func hardshrink(self Tensor, ) Tensor {
    f_hardshrink()
}

func hardshrink_backwardScalar(self Tensor, grad_out Tensor, lambd Scalar) Tensor {
    f_hardshrink_backward(grad_out, lambd)
}

func hardsigmoid(self Tensor, ) Tensor {
    f_hardsigmoid()
}

func hardsigmoid_(self Tensor, ) Tensor {
    f_hardsigmoid_()
}

func hardsigmoid_backward(self Tensor, grad_output Tensor) Tensor {
    f_hardsigmoid_backward(grad_output)
}

func hardsigmoid_out(self Tensor, out Tensor) Tensor {
    f_hardsigmoid_out(out)
}

func hardtanh(self Tensor, ) Tensor {
    f_hardtanh()
}

func hardtanh_(self Tensor, ) Tensor {
    f_hardtanh_()
}

func hardtanh_backwardScalar(self Tensor, grad_output Tensor, min_val Scalar, max_val Scalar) Tensor {
    f_hardtanh_backward(grad_output, min_val, max_val)
}

func hardtanh_backward_outScalar(self Tensor, grad_input Tensor, grad_output Tensor, min_val Scalar, max_val Scalar) Tensor {
    f_hardtanh_backward_out(grad_input, grad_output, min_val, max_val)
}

func hardtanh_out(self Tensor, out Tensor) Tensor {
    f_hardtanh_out(out)
}

func hinge_embedding_loss(self Tensor, target Tensor, margin float64, reduction int64) Tensor {
    f_hinge_embedding_loss(target, margin, reduction)
}

func histc(self Tensor, bins int64) Tensor {
    f_histc(bins)
}

func histc_out(self Tensor, out Tensor, bins int64) Tensor {
    f_histc_out(out, bins)
}

func hspmm(self Tensor, mat1 Tensor, mat2 Tensor) Tensor {
    f_hspmm(mat1, mat2)
}

func hspmm_out(self Tensor, out Tensor, mat1 Tensor, mat2 Tensor) Tensor {
    f_hspmm_out(out, mat1, mat2)
}

func ifft(self Tensor, signal_ndim int64, normalized bool) Tensor {
    f_ifft(signal_ndim, normalized)
}

func im2col(self Tensor, kernel_size []int64, dilation []int64, padding []int64, stride []int64) Tensor {
    f_im2col(kernel_size, dilation, padding, stride)
}

func im2col_backward(self Tensor, grad_output Tensor, input_size []int64, kernel_size []int64, dilation []int64, padding []int64, stride []int64) Tensor {
    f_im2col_backward(grad_output, input_size, kernel_size, dilation, padding, stride)
}

func im2col_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, input_size []int64, kernel_size []int64, dilation []int64, padding []int64, stride []int64) Tensor {
    f_im2col_backward_out(grad_input, grad_output, input_size, kernel_size, dilation, padding, stride)
}

func im2col_out(self Tensor, out Tensor, kernel_size []int64, dilation []int64, padding []int64, stride []int64) Tensor {
    f_im2col_out(out, kernel_size, dilation, padding, stride)
}

func imag(self Tensor, ) Tensor {
    f_imag()
}

func indexTensor(self Tensor, indices []Tensor) Tensor {
    f_index(indices)
}

func index_add(self Tensor, dim int64, index Tensor, source Tensor) Tensor {
    f_index_add(dim, index, source)
}

func index_add_(self Tensor, dim int64, index Tensor, source Tensor) Tensor {
    f_index_add_(dim, index, source)
}

func index_copy(self Tensor, dim int64, index Tensor, source Tensor) Tensor {
    f_index_copy(dim, index, source)
}

func index_copy_(self Tensor, dim int64, index Tensor, source Tensor) Tensor {
    f_index_copy_(dim, index, source)
}

func index_fillScalar(self Tensor, dim int64, index Tensor, value Scalar) Tensor {
    f_index_fill(dim, index, value)
}

func index_fill1(self Tensor, dim int64, index Tensor, value Tensor) Tensor {
    f_index_fill1(dim, index, value)
}

func index_fill_Scalar(self Tensor, dim int64, index Tensor, value Scalar) Tensor {
    f_index_fill_(dim, index, value)
}

func index_fill_1(self Tensor, dim int64, index Tensor, value Tensor) Tensor {
    f_index_fill_1(dim, index, value)
}

func index_putTensor(self Tensor, indices []Tensor, values Tensor, accumulate bool) Tensor {
    f_index_put(indices, values, accumulate)
}

func index_put_Tensor(self Tensor, indices []Tensor, values Tensor, accumulate bool) Tensor {
    f_index_put_(indices, values, accumulate)
}

func index_select(self Tensor, dim int64, index Tensor) Tensor {
    f_index_select(dim, index)
}

func index_select_out(self Tensor, out Tensor, dim int64, index Tensor) Tensor {
    f_index_select_out(out, dim, index)
}

func indices(self Tensor, ) Tensor {
    f_indices()
}

func instance_normTensor(self Tensor, input Tensor, weight TensorOption, bias TensorOption, running_mean TensorOption, running_var TensorOption, use_input_stats bool, momentum float64, eps float64, cudnn_enabled bool) Tensor {
    f_instance_norm(input, weight, bias, running_mean, running_var, use_input_stats, momentum, eps, cudnn_enabled)
}

func int_repr(self Tensor, ) Tensor {
    f_int_repr()
}

func inverse(self Tensor, ) Tensor {
    f_inverse()
}

func inverse_out(self Tensor, out Tensor) Tensor {
    f_inverse_out(out)
}

func irfft(self Tensor, signal_ndim int64, normalized bool, onesided bool, signal_sizes []int64) Tensor {
    f_irfft(signal_ndim, normalized, onesided, signal_sizes)
}

func isclose(self Tensor, other Tensor, rtol float64, atol float64, equal_nan bool) Tensor {
    f_isclose(other, rtol, atol, equal_nan)
}

func isfinite(self Tensor, ) Tensor {
    f_isfinite()
}

func isinf(self Tensor, ) Tensor {
    f_isinf()
}

func isnan(self Tensor, ) Tensor {
    f_isnan()
}

func kl_div(self Tensor, target Tensor, reduction int64) Tensor {
    f_kl_div(target, reduction)
}

func kl_div_backward(self Tensor, grad_output Tensor, target Tensor, reduction int64) Tensor {
    f_kl_div_backward(grad_output, target, reduction)
}

func kthvalue(self Tensor, k int64, dim int64, keepdim bool) (Tensor, Tensor) {
    f_kthvalue(k, dim, keepdim)
}

func kthvalue_out(self Tensor, values Tensor, indices Tensor, k int64, dim int64, keepdim bool) (Tensor, Tensor) {
    f_kthvalue_out(values, indices, k, dim, keepdim)
}

func l1_loss(self Tensor, target Tensor, reduction int64) Tensor {
    f_l1_loss(target, reduction)
}

func l1_loss_backward(self Tensor, grad_output Tensor, target Tensor, reduction int64) Tensor {
    f_l1_loss_backward(grad_output, target, reduction)
}

func l1_loss_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, target Tensor, reduction int64) Tensor {
    f_l1_loss_backward_out(grad_input, grad_output, target, reduction)
}

func l1_loss_out(self Tensor, out Tensor, target Tensor, reduction int64) Tensor {
    f_l1_loss_out(out, target, reduction)
}

func layer_normTensor(self Tensor, input Tensor, normalized_shape []int64, weight TensorOption, bias TensorOption, eps float64, cudnn_enable bool) Tensor {
    f_layer_norm(input, normalized_shape, weight, bias, eps, cudnn_enable)
}

func leScalar(self Tensor, other Scalar) Tensor {
    f_le(other)
}

func le1(self Tensor, other Tensor) Tensor {
    f_le1(other)
}

func le_Scalar(self Tensor, other Scalar) Tensor {
    f_le_(other)
}

func le_1(self Tensor, other Tensor) Tensor {
    f_le_1(other)
}

func le_outScalar(self Tensor, out Tensor, other Scalar) Tensor {
    f_le_out(out, other)
}

func le_out1(self Tensor, out Tensor, other Tensor) Tensor {
    f_le_out1(out, other)
}

func leaky_relu(self Tensor, ) Tensor {
    f_leaky_relu()
}

func leaky_relu_(self Tensor, ) Tensor {
    f_leaky_relu_()
}

func leaky_relu_backwardScalar(self Tensor, grad_output Tensor, negative_slope Scalar, self_is_result bool) Tensor {
    f_leaky_relu_backward(grad_output, negative_slope, self_is_result)
}

func leaky_relu_out(self Tensor, out Tensor) Tensor {
    f_leaky_relu_out(out)
}

func lerpScalar(self Tensor, end Tensor, weight Scalar) Tensor {
    f_lerp(end, weight)
}

func lerp1(self Tensor, end Tensor, weight Tensor) Tensor {
    f_lerp1(end, weight)
}

func lerp_Scalar(self Tensor, end Tensor, weight Scalar) Tensor {
    f_lerp_(end, weight)
}

func lerp_1(self Tensor, end Tensor, weight Tensor) Tensor {
    f_lerp_1(end, weight)
}

func lerp_outScalar(self Tensor, out Tensor, end Tensor, weight Scalar) Tensor {
    f_lerp_out(out, end, weight)
}

func lerp_out1(self Tensor, out Tensor, end Tensor, weight Tensor) Tensor {
    f_lerp_out1(out, end, weight)
}

func lgamma(self Tensor, ) Tensor {
    f_lgamma()
}

func lgamma_(self Tensor, ) Tensor {
    f_lgamma_()
}

func lgamma_out(self Tensor, out Tensor) Tensor {
    f_lgamma_out(out)
}

func linearTensor(self Tensor, input Tensor, weight Tensor, bias TensorOption) Tensor {
    f_linear(input, weight, bias)
}

func linspaceScalar(self Tensor, start Scalar, end Scalar, steps int64, options (Kind, Device)) Tensor {
    f_linspace(start, end, steps, options)
}

func linspace_outScalar(self Tensor, out Tensor, start Scalar, end Scalar, steps int64) Tensor {
    f_linspace_out(out, start, end, steps)
}

func log(self Tensor, ) Tensor {
    f_log()
}

func log10(self Tensor, ) Tensor {
    f_log10()
}

func log10_(self Tensor, ) Tensor {
    f_log10_()
}

func log10_out(self Tensor, out Tensor) Tensor {
    f_log10_out(out)
}

func log1p(self Tensor, ) Tensor {
    f_log1p()
}

func log1p_(self Tensor, ) Tensor {
    f_log1p_()
}

func log1p_out(self Tensor, out Tensor) Tensor {
    f_log1p_out(out)
}

func log2(self Tensor, ) Tensor {
    f_log2()
}

func log2_(self Tensor, ) Tensor {
    f_log2_()
}

func log2_out(self Tensor, out Tensor) Tensor {
    f_log2_out(out)
}

func log_(self Tensor, ) Tensor {
    f_log_()
}

func log_normal_(self Tensor, mean float64, std float64) Tensor {
    f_log_normal_(mean, std)
}

func log_out(self Tensor, out Tensor) Tensor {
    f_log_out(out)
}

func log_sigmoid(self Tensor, ) Tensor {
    f_log_sigmoid()
}

func log_sigmoid_backward(self Tensor, grad_output Tensor, buffer Tensor) Tensor {
    f_log_sigmoid_backward(grad_output, buffer)
}

func log_sigmoid_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, buffer Tensor) Tensor {
    f_log_sigmoid_backward_out(grad_input, grad_output, buffer)
}

func log_sigmoid_out(self Tensor, out Tensor) Tensor {
    f_log_sigmoid_out(out)
}

func log_softmax(self Tensor, dim int64, dtype Kind) Tensor {
    f_log_softmax(dim, dtype)
}

func logdet(self Tensor, ) Tensor {
    f_logdet()
}

func logical_and(self Tensor, other Tensor) Tensor {
    f_logical_and(other)
}

func logical_and_(self Tensor, other Tensor) Tensor {
    f_logical_and_(other)
}

func logical_and_out(self Tensor, out Tensor, other Tensor) Tensor {
    f_logical_and_out(out, other)
}

func logical_not(self Tensor, ) Tensor {
    f_logical_not()
}

func logical_not_(self Tensor, ) Tensor {
    f_logical_not_()
}

func logical_not_out(self Tensor, out Tensor) Tensor {
    f_logical_not_out(out)
}

func logical_or(self Tensor, other Tensor) Tensor {
    f_logical_or(other)
}

func logical_or_(self Tensor, other Tensor) Tensor {
    f_logical_or_(other)
}

func logical_or_out(self Tensor, out Tensor, other Tensor) Tensor {
    f_logical_or_out(out, other)
}

func logical_xor(self Tensor, other Tensor) Tensor {
    f_logical_xor(other)
}

func logical_xor_(self Tensor, other Tensor) Tensor {
    f_logical_xor_(other)
}

func logical_xor_out(self Tensor, out Tensor, other Tensor) Tensor {
    f_logical_xor_out(out, other)
}

func logspaceScalar(self Tensor, start Scalar, end Scalar, steps int64, base float64, options (Kind, Device)) Tensor {
    f_logspace(start, end, steps, base, options)
}

func logspace_outScalar(self Tensor, out Tensor, start Scalar, end Scalar, steps int64, base float64) Tensor {
    f_logspace_out(out, start, end, steps, base)
}

func logsumexp(self Tensor, dim []int64, keepdim bool) Tensor {
    f_logsumexp(dim, keepdim)
}

func logsumexp_out(self Tensor, out Tensor, dim []int64, keepdim bool) Tensor {
    f_logsumexp_out(out, dim, keepdim)
}

func lstmTensor(self Tensor, input Tensor, hx []Tensor, params []Tensor, has_biases bool, num_layers int64, dropout float64, train bool, bidirectional bool, batch_first bool) (Tensor, Tensor, Tensor) {
    f_lstm(input, hx, params, has_biases, num_layers, dropout, train, bidirectional, batch_first)
}

func lstm1Tensor(self Tensor, data Tensor, batch_sizes Tensor, hx []Tensor, params []Tensor, has_biases bool, num_layers int64, dropout float64, train bool, bidirectional bool) (Tensor, Tensor, Tensor) {
    f_lstm1(data, batch_sizes, hx, params, has_biases, num_layers, dropout, train, bidirectional)
}

func lstm_cellTensor(self Tensor, input Tensor, hx []Tensor, w_ih Tensor, w_hh Tensor, b_ih TensorOption, b_hh TensorOption) (Tensor, Tensor) {
    f_lstm_cell(input, hx, w_ih, w_hh, b_ih, b_hh)
}

func lstsq(self Tensor, a Tensor) (Tensor, Tensor) {
    f_lstsq(a)
}

func lstsq_out(self Tensor, x Tensor, qr Tensor, a Tensor) (Tensor, Tensor) {
    f_lstsq_out(x, qr, a)
}

func ltScalar(self Tensor, other Scalar) Tensor {
    f_lt(other)
}

func lt1(self Tensor, other Tensor) Tensor {
    f_lt1(other)
}

func lt_Scalar(self Tensor, other Scalar) Tensor {
    f_lt_(other)
}

func lt_1(self Tensor, other Tensor) Tensor {
    f_lt_1(other)
}

func lt_outScalar(self Tensor, out Tensor, other Scalar) Tensor {
    f_lt_out(out, other)
}

func lt_out1(self Tensor, out Tensor, other Tensor) Tensor {
    f_lt_out1(out, other)
}

func lu_solve(self Tensor, lu_data Tensor, lu_pivots Tensor) Tensor {
    f_lu_solve(lu_data, lu_pivots)
}

func lu_solve_out(self Tensor, out Tensor, lu_data Tensor, lu_pivots Tensor) Tensor {
    f_lu_solve_out(out, lu_data, lu_pivots)
}

func margin_ranking_loss(self Tensor, input1 Tensor, input2 Tensor, target Tensor, margin float64, reduction int64) Tensor {
    f_margin_ranking_loss(input1, input2, target, margin, reduction)
}

func masked_fillScalar(self Tensor, mask Tensor, value Scalar) Tensor {
    f_masked_fill(mask, value)
}

func masked_fill1(self Tensor, mask Tensor, value Tensor) Tensor {
    f_masked_fill1(mask, value)
}

func masked_fill_Scalar(self Tensor, mask Tensor, value Scalar) Tensor {
    f_masked_fill_(mask, value)
}

func masked_fill_1(self Tensor, mask Tensor, value Tensor) Tensor {
    f_masked_fill_1(mask, value)
}

func masked_scatter(self Tensor, mask Tensor, source Tensor) Tensor {
    f_masked_scatter(mask, source)
}

func masked_scatter_(self Tensor, mask Tensor, source Tensor) Tensor {
    f_masked_scatter_(mask, source)
}

func masked_select(self Tensor, mask Tensor) Tensor {
    f_masked_select(mask)
}

func masked_select_out(self Tensor, out Tensor, mask Tensor) Tensor {
    f_masked_select_out(out, mask)
}

func matmul(self Tensor, other Tensor) Tensor {
    f_matmul(other)
}

func matmul_out(self Tensor, out Tensor, other Tensor) Tensor {
    f_matmul_out(out, other)
}

func matrix_power(self Tensor, n int64) Tensor {
    f_matrix_power(n)
}

func matrix_rank(self Tensor, symmetric bool) Tensor {
    f_matrix_rank(symmetric)
}

func matrix_rank1(self Tensor, tol float64, symmetric bool) Tensor {
    f_matrix_rank1(tol, symmetric)
}

func max(self Tensor, ) Tensor {
    f_max()
}

func max1(self Tensor, other Tensor) Tensor {
    f_max1(other)
}

func max2(self Tensor, dim int64, keepdim bool) (Tensor, Tensor) {
    f_max2(dim, keepdim)
}

func max_out(self Tensor, out Tensor, other Tensor) Tensor {
    f_max_out(out, other)
}

func max_out1(self Tensor, max Tensor, max_values Tensor, dim int64, keepdim bool) (Tensor, Tensor) {
    f_max_out1(max, max_values, dim, keepdim)
}

func max_pool1d(self Tensor, kernel_size []int64, stride []int64, padding []int64, dilation []int64, ceil_mode bool) Tensor {
    f_max_pool1d(kernel_size, stride, padding, dilation, ceil_mode)
}

func max_pool1d_with_indices(self Tensor, kernel_size []int64, stride []int64, padding []int64, dilation []int64, ceil_mode bool) (Tensor, Tensor) {
    f_max_pool1d_with_indices(kernel_size, stride, padding, dilation, ceil_mode)
}

func max_pool2d(self Tensor, kernel_size []int64, stride []int64, padding []int64, dilation []int64, ceil_mode bool) Tensor {
    f_max_pool2d(kernel_size, stride, padding, dilation, ceil_mode)
}

func max_pool2d_with_indices(self Tensor, kernel_size []int64, stride []int64, padding []int64, dilation []int64, ceil_mode bool) (Tensor, Tensor) {
    f_max_pool2d_with_indices(kernel_size, stride, padding, dilation, ceil_mode)
}

func max_pool2d_with_indices_backward(self Tensor, grad_output Tensor, kernel_size []int64, stride []int64, padding []int64, dilation []int64, ceil_mode bool, indices Tensor) Tensor {
    f_max_pool2d_with_indices_backward(grad_output, kernel_size, stride, padding, dilation, ceil_mode, indices)
}

func max_pool2d_with_indices_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, kernel_size []int64, stride []int64, padding []int64, dilation []int64, ceil_mode bool, indices Tensor) Tensor {
    f_max_pool2d_with_indices_backward_out(grad_input, grad_output, kernel_size, stride, padding, dilation, ceil_mode, indices)
}

func max_pool2d_with_indices_out(self Tensor, out Tensor, indices Tensor, kernel_size []int64, stride []int64, padding []int64, dilation []int64, ceil_mode bool) (Tensor, Tensor) {
    f_max_pool2d_with_indices_out(out, indices, kernel_size, stride, padding, dilation, ceil_mode)
}

func max_pool3d(self Tensor, kernel_size []int64, stride []int64, padding []int64, dilation []int64, ceil_mode bool) Tensor {
    f_max_pool3d(kernel_size, stride, padding, dilation, ceil_mode)
}

func max_pool3d_with_indices(self Tensor, kernel_size []int64, stride []int64, padding []int64, dilation []int64, ceil_mode bool) (Tensor, Tensor) {
    f_max_pool3d_with_indices(kernel_size, stride, padding, dilation, ceil_mode)
}

func max_pool3d_with_indices_backward(self Tensor, grad_output Tensor, kernel_size []int64, stride []int64, padding []int64, dilation []int64, ceil_mode bool, indices Tensor) Tensor {
    f_max_pool3d_with_indices_backward(grad_output, kernel_size, stride, padding, dilation, ceil_mode, indices)
}

func max_pool3d_with_indices_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, kernel_size []int64, stride []int64, padding []int64, dilation []int64, ceil_mode bool, indices Tensor) Tensor {
    f_max_pool3d_with_indices_backward_out(grad_input, grad_output, kernel_size, stride, padding, dilation, ceil_mode, indices)
}

func max_pool3d_with_indices_out(self Tensor, out Tensor, indices Tensor, kernel_size []int64, stride []int64, padding []int64, dilation []int64, ceil_mode bool) (Tensor, Tensor) {
    f_max_pool3d_with_indices_out(out, indices, kernel_size, stride, padding, dilation, ceil_mode)
}

func max_unpool2d(self Tensor, indices Tensor, output_size []int64) Tensor {
    f_max_unpool2d(indices, output_size)
}

func max_unpool2d_backward(self Tensor, grad_output Tensor, indices Tensor, output_size []int64) Tensor {
    f_max_unpool2d_backward(grad_output, indices, output_size)
}

func max_unpool2d_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, indices Tensor, output_size []int64) Tensor {
    f_max_unpool2d_backward_out(grad_input, grad_output, indices, output_size)
}

func max_unpool2d_out(self Tensor, out Tensor, indices Tensor, output_size []int64) Tensor {
    f_max_unpool2d_out(out, indices, output_size)
}

func max_unpool3d(self Tensor, indices Tensor, output_size []int64, stride []int64, padding []int64) Tensor {
    f_max_unpool3d(indices, output_size, stride, padding)
}

func max_unpool3d_backward(self Tensor, grad_output Tensor, indices Tensor, output_size []int64, stride []int64, padding []int64) Tensor {
    f_max_unpool3d_backward(grad_output, indices, output_size, stride, padding)
}

func max_unpool3d_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, indices Tensor, output_size []int64, stride []int64, padding []int64) Tensor {
    f_max_unpool3d_backward_out(grad_input, grad_output, indices, output_size, stride, padding)
}

func max_unpool3d_out(self Tensor, out Tensor, indices Tensor, output_size []int64, stride []int64, padding []int64) Tensor {
    f_max_unpool3d_out(out, indices, output_size, stride, padding)
}

func max_values(self Tensor, dim []int64, keepdim bool) Tensor {
    f_max_values(dim, keepdim)
}

func mean(self Tensor, dtype Kind) Tensor {
    f_mean(dtype)
}

func mean1(self Tensor, dim []int64, keepdim bool, dtype Kind) Tensor {
    f_mean1(dim, keepdim, dtype)
}

func mean_out(self Tensor, out Tensor, dim []int64, keepdim bool, dtype Kind) Tensor {
    f_mean_out(out, dim, keepdim, dtype)
}

func median(self Tensor, ) Tensor {
    f_median()
}

func median1(self Tensor, dim int64, keepdim bool) (Tensor, Tensor) {
    f_median1(dim, keepdim)
}

func median_out(self Tensor, values Tensor, indices Tensor, dim int64, keepdim bool) (Tensor, Tensor) {
    f_median_out(values, indices, dim, keepdim)
}

func meshgridTensor(self Tensor, tensors []Tensor) []Tensor {
    f_meshgrid(tensors)
}

func min(self Tensor, ) Tensor {
    f_min()
}

func min1(self Tensor, other Tensor) Tensor {
    f_min1(other)
}

func min2(self Tensor, dim int64, keepdim bool) (Tensor, Tensor) {
    f_min2(dim, keepdim)
}

func min_out(self Tensor, out Tensor, other Tensor) Tensor {
    f_min_out(out, other)
}

func min_out1(self Tensor, min Tensor, min_indices Tensor, dim int64, keepdim bool) (Tensor, Tensor) {
    f_min_out1(min, min_indices, dim, keepdim)
}

func min_values(self Tensor, dim []int64, keepdim bool) Tensor {
    f_min_values(dim, keepdim)
}

func miopen_batch_normTensor(self Tensor, input Tensor, weight Tensor, bias TensorOption, running_mean TensorOption, running_var TensorOption, training bool, exponential_average_factor float64, epsilon float64) (Tensor, Tensor, Tensor) {
    f_miopen_batch_norm(input, weight, bias, running_mean, running_var, training, exponential_average_factor, epsilon)
}

func miopen_batch_norm_backwardTensor(self Tensor, input Tensor, grad_output Tensor, weight Tensor, running_mean TensorOption, running_var TensorOption, save_mean TensorOption, save_var TensorOption, epsilon float64) (Tensor, Tensor, Tensor) {
    f_miopen_batch_norm_backward(input, grad_output, weight, running_mean, running_var, save_mean, save_var, epsilon)
}

func miopen_convolutionTensor(self Tensor, weight Tensor, bias TensorOption, padding []int64, stride []int64, dilation []int64, groups int64, benchmark bool, deterministic bool) Tensor {
    f_miopen_convolution(weight, bias, padding, stride, dilation, groups, benchmark, deterministic)
}

func miopen_convolution_backward_bias(self Tensor, grad_output Tensor) Tensor {
    f_miopen_convolution_backward_bias(grad_output)
}

func miopen_convolution_backward_input(self Tensor, self_size []int64, grad_output Tensor, weight Tensor, padding []int64, stride []int64, dilation []int64, groups int64, benchmark bool, deterministic bool) Tensor {
    f_miopen_convolution_backward_input(self_size, grad_output, weight, padding, stride, dilation, groups, benchmark, deterministic)
}

func miopen_convolution_backward_weight(self Tensor, weight_size []int64, grad_output Tensor, padding []int64, stride []int64, dilation []int64, groups int64, benchmark bool, deterministic bool) Tensor {
    f_miopen_convolution_backward_weight(weight_size, grad_output, padding, stride, dilation, groups, benchmark, deterministic)
}

func miopen_convolution_transposeTensor(self Tensor, weight Tensor, bias TensorOption, padding []int64, output_padding []int64, stride []int64, dilation []int64, groups int64, benchmark bool, deterministic bool) Tensor {
    f_miopen_convolution_transpose(weight, bias, padding, output_padding, stride, dilation, groups, benchmark, deterministic)
}

func miopen_convolution_transpose_backward_input(self Tensor, grad_output Tensor, weight Tensor, padding []int64, stride []int64, dilation []int64, groups int64, benchmark bool, deterministic bool) Tensor {
    f_miopen_convolution_transpose_backward_input(grad_output, weight, padding, stride, dilation, groups, benchmark, deterministic)
}

func miopen_convolution_transpose_backward_weight(self Tensor, weight_size []int64, grad_output Tensor, padding []int64, stride []int64, dilation []int64, groups int64, benchmark bool, deterministic bool) Tensor {
    f_miopen_convolution_transpose_backward_weight(weight_size, grad_output, padding, stride, dilation, groups, benchmark, deterministic)
}

func miopen_depthwise_convolutionTensor(self Tensor, weight Tensor, bias TensorOption, padding []int64, stride []int64, dilation []int64, groups int64, benchmark bool, deterministic bool) Tensor {
    f_miopen_depthwise_convolution(weight, bias, padding, stride, dilation, groups, benchmark, deterministic)
}

func miopen_depthwise_convolution_backward_input(self Tensor, self_size []int64, grad_output Tensor, weight Tensor, padding []int64, stride []int64, dilation []int64, groups int64, benchmark bool, deterministic bool) Tensor {
    f_miopen_depthwise_convolution_backward_input(self_size, grad_output, weight, padding, stride, dilation, groups, benchmark, deterministic)
}

func miopen_depthwise_convolution_backward_weight(self Tensor, weight_size []int64, grad_output Tensor, padding []int64, stride []int64, dilation []int64, groups int64, benchmark bool, deterministic bool) Tensor {
    f_miopen_depthwise_convolution_backward_weight(weight_size, grad_output, padding, stride, dilation, groups, benchmark, deterministic)
}

func miopen_rnnTensor(self Tensor, input Tensor, weight []Tensor, weight_stride0 int64, hx Tensor, cx TensorOption, mode int64, hidden_size int64, num_layers int64, batch_first bool, dropout float64, train bool, bidirectional bool, batch_sizes []int64, dropout_state TensorOption) (Tensor, Tensor, Tensor, Tensor, Tensor) {
    f_miopen_rnn(input, weight, weight_stride0, hx, cx, mode, hidden_size, num_layers, batch_first, dropout, train, bidirectional, batch_sizes, dropout_state)
}

func mkldnn_adaptive_avg_pool2d(self Tensor, output_size []int64) Tensor {
    f_mkldnn_adaptive_avg_pool2d(output_size)
}

func mkldnn_convolutionTensor(self Tensor, weight Tensor, bias TensorOption, padding []int64, stride []int64, dilation []int64, groups int64) Tensor {
    f_mkldnn_convolution(weight, bias, padding, stride, dilation, groups)
}

func mkldnn_convolution_backward_input(self Tensor, self_size []int64, grad_output Tensor, weight Tensor, padding []int64, stride []int64, dilation []int64, groups int64, bias_defined bool) Tensor {
    f_mkldnn_convolution_backward_input(self_size, grad_output, weight, padding, stride, dilation, groups, bias_defined)
}

func mkldnn_convolution_backward_weights(self Tensor, weight_size []int64, grad_output Tensor, padding []int64, stride []int64, dilation []int64, groups int64, bias_defined bool) (Tensor, Tensor) {
    f_mkldnn_convolution_backward_weights(weight_size, grad_output, padding, stride, dilation, groups, bias_defined)
}

func mkldnn_linearTensor(self Tensor, input Tensor, weight Tensor, bias TensorOption) Tensor {
    f_mkldnn_linear(input, weight, bias)
}

func mkldnn_max_pool2d(self Tensor, kernel_size []int64, stride []int64, padding []int64, dilation []int64, ceil_mode bool) Tensor {
    f_mkldnn_max_pool2d(kernel_size, stride, padding, dilation, ceil_mode)
}

func mkldnn_reorder_conv2d_weight(self Tensor, padding []int64, stride []int64, dilation []int64, groups int64) Tensor {
    f_mkldnn_reorder_conv2d_weight(padding, stride, dilation, groups)
}

func mm(self Tensor, mat2 Tensor) Tensor {
    f_mm(mat2)
}

func mm_out(self Tensor, out Tensor, mat2 Tensor) Tensor {
    f_mm_out(out, mat2)
}

func mode(self Tensor, dim int64, keepdim bool) (Tensor, Tensor) {
    f_mode(dim, keepdim)
}

func mode_out(self Tensor, values Tensor, indices Tensor, dim int64, keepdim bool) (Tensor, Tensor) {
    f_mode_out(values, indices, dim, keepdim)
}

func mse_loss(self Tensor, target Tensor, reduction int64) Tensor {
    f_mse_loss(target, reduction)
}

func mse_loss_backward(self Tensor, grad_output Tensor, target Tensor, reduction int64) Tensor {
    f_mse_loss_backward(grad_output, target, reduction)
}

func mse_loss_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, target Tensor, reduction int64) Tensor {
    f_mse_loss_backward_out(grad_input, grad_output, target, reduction)
}

func mse_loss_out(self Tensor, out Tensor, target Tensor, reduction int64) Tensor {
    f_mse_loss_out(out, target, reduction)
}

func g_mul(self Tensor, other Tensor) Tensor {
    f_mul(other)
}

func g_mul1Scalar(self Tensor, other Scalar) Tensor {
    f_mul1(other)
}

func g_mul_(self Tensor, other Tensor) Tensor {
    f_mul_(other)
}

func g_mul_1Scalar(self Tensor, other Scalar) Tensor {
    f_mul_1(other)
}

func mul_out(self Tensor, out Tensor, other Tensor) Tensor {
    f_mul_out(out, other)
}

func multi_margin_loss_backwardTensor, Scalar(self Tensor, grad_output Tensor, target Tensor, p Scalar, margin Scalar, weight TensorOption, reduction int64) Tensor {
    f_multi_margin_loss_backward(grad_output, target, p, margin, weight, reduction)
}

func multi_margin_loss_backward_outTensor, Scalar(self Tensor, grad_input Tensor, grad_output Tensor, target Tensor, p Scalar, margin Scalar, weight TensorOption, reduction int64) Tensor {
    f_multi_margin_loss_backward_out(grad_input, grad_output, target, p, margin, weight, reduction)
}

func multilabel_margin_loss(self Tensor, target Tensor, reduction int64) Tensor {
    f_multilabel_margin_loss(target, reduction)
}

func multilabel_margin_loss_backward(self Tensor, grad_output Tensor, target Tensor, reduction int64, is_target Tensor) Tensor {
    f_multilabel_margin_loss_backward(grad_output, target, reduction, is_target)
}

func multilabel_margin_loss_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, target Tensor, reduction int64, is_target Tensor) Tensor {
    f_multilabel_margin_loss_backward_out(grad_input, grad_output, target, reduction, is_target)
}

func multilabel_margin_loss_out(self Tensor, out Tensor, target Tensor, reduction int64) Tensor {
    f_multilabel_margin_loss_out(out, target, reduction)
}

func multinomial(self Tensor, num_samples int64, replacement bool) Tensor {
    f_multinomial(num_samples, replacement)
}

func multinomial_out(self Tensor, out Tensor, num_samples int64, replacement bool) Tensor {
    f_multinomial_out(out, num_samples, replacement)
}

func mv(self Tensor, vec Tensor) Tensor {
    f_mv(vec)
}

func mv_out(self Tensor, out Tensor, vec Tensor) Tensor {
    f_mv_out(out, vec)
}

func mvlgamma(self Tensor, p int64) Tensor {
    f_mvlgamma(p)
}

func mvlgamma_(self Tensor, p int64) Tensor {
    f_mvlgamma_(p)
}

func narrow(self Tensor, dim int64, start int64, length int64) Tensor {
    f_narrow(dim, start, length)
}

func narrow1(self Tensor, dim int64, start Tensor, length int64) Tensor {
    f_narrow1(dim, start, length)
}

func narrow_copy(self Tensor, dim int64, start int64, length int64) Tensor {
    f_narrow_copy(dim, start, length)
}

func native_batch_normTensor(self Tensor, input Tensor, weight TensorOption, bias TensorOption, running_mean TensorOption, running_var TensorOption, training bool, momentum float64, eps float64) (Tensor, Tensor, Tensor) {
    f_native_batch_norm(input, weight, bias, running_mean, running_var, training, momentum, eps)
}

func native_batch_norm_outTensor(self Tensor, out Tensor, save_mean Tensor, save_invstd Tensor, input Tensor, weight TensorOption, bias TensorOption, running_mean TensorOption, running_var TensorOption, training bool, momentum float64, eps float64) (Tensor, Tensor, Tensor) {
    f_native_batch_norm_out(out, save_mean, save_invstd, input, weight, bias, running_mean, running_var, training, momentum, eps)
}

func native_layer_normTensor(self Tensor, input Tensor, weight TensorOption, bias TensorOption, m int64, n int64, eps float64) (Tensor, Tensor, Tensor) {
    f_native_layer_norm(input, weight, bias, m, n, eps)
}

func native_norm(self Tensor, ) Tensor {
    f_native_norm()
}

func neScalar(self Tensor, other Scalar) Tensor {
    f_ne(other)
}

func ne1(self Tensor, other Tensor) Tensor {
    f_ne1(other)
}

func ne_Scalar(self Tensor, other Scalar) Tensor {
    f_ne_(other)
}

func ne_1(self Tensor, other Tensor) Tensor {
    f_ne_1(other)
}

func ne_outScalar(self Tensor, out Tensor, other Scalar) Tensor {
    f_ne_out(out, other)
}

func ne_out1(self Tensor, out Tensor, other Tensor) Tensor {
    f_ne_out1(out, other)
}

func neg(self Tensor, ) Tensor {
    f_neg()
}

func neg_(self Tensor, ) Tensor {
    f_neg_()
}

func neg_out(self Tensor, out Tensor) Tensor {
    f_neg_out(out)
}

func new_empty(self Tensor, size []int64, options (Kind, Device)) Tensor {
    f_new_empty(size, options)
}

func new_fullScalar(self Tensor, size []int64, fill_value Scalar, options (Kind, Device)) Tensor {
    f_new_full(size, fill_value, options)
}

func new_zeros(self Tensor, size []int64, options (Kind, Device)) Tensor {
    f_new_zeros(size, options)
}

func g_nll_lossTensor(self Tensor, target Tensor, weight TensorOption, reduction int64, ignore_index int64) Tensor {
    f_nll_loss(target, weight, reduction, ignore_index)
}

func nll_loss2dTensor(self Tensor, target Tensor, weight TensorOption, reduction int64, ignore_index int64) Tensor {
    f_nll_loss2d(target, weight, reduction, ignore_index)
}

func nll_loss2d_backwardTensor(self Tensor, grad_output Tensor, target Tensor, weight TensorOption, reduction int64, ignore_index int64, total_weight Tensor) Tensor {
    f_nll_loss2d_backward(grad_output, target, weight, reduction, ignore_index, total_weight)
}

func nll_loss2d_backward_outTensor(self Tensor, grad_input Tensor, grad_output Tensor, target Tensor, weight TensorOption, reduction int64, ignore_index int64, total_weight Tensor) Tensor {
    f_nll_loss2d_backward_out(grad_input, grad_output, target, weight, reduction, ignore_index, total_weight)
}

func nll_loss2d_outTensor(self Tensor, out Tensor, target Tensor, weight TensorOption, reduction int64, ignore_index int64) Tensor {
    f_nll_loss2d_out(out, target, weight, reduction, ignore_index)
}

func nll_loss_backwardTensor(self Tensor, grad_output Tensor, target Tensor, weight TensorOption, reduction int64, ignore_index int64, total_weight Tensor) Tensor {
    f_nll_loss_backward(grad_output, target, weight, reduction, ignore_index, total_weight)
}

func nll_loss_backward_outTensor(self Tensor, grad_input Tensor, grad_output Tensor, target Tensor, weight TensorOption, reduction int64, ignore_index int64, total_weight Tensor) Tensor {
    f_nll_loss_backward_out(grad_input, grad_output, target, weight, reduction, ignore_index, total_weight)
}

func nll_loss_outTensor(self Tensor, out Tensor, target Tensor, weight TensorOption, reduction int64, ignore_index int64) Tensor {
    f_nll_loss_out(out, target, weight, reduction, ignore_index)
}

func nonzero(self Tensor, ) Tensor {
    f_nonzero()
}

func nonzero_numpy(self Tensor, ) []Tensor {
    f_nonzero_numpy()
}

func nonzero_out(self Tensor, out Tensor) Tensor {
    f_nonzero_out(out)
}

func norm(self Tensor, ) Tensor {
    f_norm()
}

func norm1Scalar(self Tensor, p Scalar, dtype Kind) Tensor {
    f_norm1(p, dtype)
}

func norm2Scalar(self Tensor, p Scalar, dim []int64, keepdim bool) Tensor {
    f_norm2(p, dim, keepdim)
}

func norm3Scalar(self Tensor, p Scalar, dim []int64, keepdim bool, dtype Kind) Tensor {
    f_norm3(p, dim, keepdim, dtype)
}

func norm_except_dim(self Tensor, v Tensor, pow int64, dim int64) Tensor {
    f_norm_except_dim(v, pow, dim)
}

func norm_outScalar(self Tensor, out Tensor, p Scalar, dim []int64, keepdim bool) Tensor {
    f_norm_out(out, p, dim, keepdim)
}

func norm_out1Scalar(self Tensor, out Tensor, p Scalar, dim []int64, keepdim bool, dtype Kind) Tensor {
    f_norm_out1(out, p, dim, keepdim, dtype)
}

func normal_(self Tensor, mean float64, std float64) Tensor {
    f_normal_(mean, std)
}

func normal_out(self Tensor, out Tensor, mean Tensor, std float64) Tensor {
    f_normal_out(out, mean, std)
}

func normal_out1(self Tensor, out Tensor, mean float64, std Tensor) Tensor {
    f_normal_out1(out, mean, std)
}

func normal_out2(self Tensor, out Tensor, mean Tensor, std Tensor) Tensor {
    f_normal_out2(out, mean, std)
}

func normal_out3(self Tensor, out Tensor, mean float64, std float64, size []int64) Tensor {
    f_normal_out3(out, mean, std, size)
}

func nuclear_norm(self Tensor, keepdim bool) Tensor {
    f_nuclear_norm(keepdim)
}

func nuclear_norm1(self Tensor, dim []int64, keepdim bool) Tensor {
    f_nuclear_norm1(dim, keepdim)
}

func nuclear_norm_out(self Tensor, out Tensor, keepdim bool) Tensor {
    f_nuclear_norm_out(out, keepdim)
}

func nuclear_norm_out1(self Tensor, out Tensor, dim []int64, keepdim bool) Tensor {
    f_nuclear_norm_out1(out, dim, keepdim)
}

func numpy_t(self Tensor, ) Tensor {
    f_numpy_t()
}

func one_hot(self Tensor, num_classes int64) Tensor {
    f_one_hot(num_classes)
}

func ones(self Tensor, size []int64, options (Kind, Device)) Tensor {
    f_ones(size, options)
}

func ones_like(self Tensor, ) Tensor {
    f_ones_like()
}

func ones_out(self Tensor, out Tensor, size []int64) Tensor {
    f_ones_out(out, size)
}

func orgqr(self Tensor, input2 Tensor) Tensor {
    f_orgqr(input2)
}

func orgqr_out(self Tensor, out Tensor, input2 Tensor) Tensor {
    f_orgqr_out(out, input2)
}

func ormqr(self Tensor, input2 Tensor, input3 Tensor, left bool, transpose bool) Tensor {
    f_ormqr(input2, input3, left, transpose)
}

func ormqr_out(self Tensor, out Tensor, input2 Tensor, input3 Tensor, left bool, transpose bool) Tensor {
    f_ormqr_out(out, input2, input3, left, transpose)
}

func pairwise_distance(self Tensor, x1 Tensor, x2 Tensor, p float64, eps float64, keepdim bool) Tensor {
    f_pairwise_distance(x1, x2, p, eps, keepdim)
}

func pdist(self Tensor, p float64) Tensor {
    f_pdist(p)
}

func permute(self Tensor, dims []int64) Tensor {
    f_permute(dims)
}

func pin_memory(self Tensor, ) Tensor {
    f_pin_memory()
}

func pinverse(self Tensor, rcond float64) Tensor {
    f_pinverse(rcond)
}

func pixel_shuffle(self Tensor, upscale_factor int64) Tensor {
    f_pixel_shuffle(upscale_factor)
}

func poisson(self Tensor, ) Tensor {
    f_poisson()
}

func poisson_nll_loss(self Tensor, input Tensor, target Tensor, log_input bool, full bool, eps float64, reduction int64) Tensor {
    f_poisson_nll_loss(input, target, log_input, full, eps, reduction)
}

func polygamma(self Tensor, n int64) Tensor {
    f_polygamma(n)
}

func polygamma_(self Tensor, n int64) Tensor {
    f_polygamma_(n)
}

func polygamma_out(self Tensor, out Tensor, n int64) Tensor {
    f_polygamma_out(out, n)
}

func powScalar(self Tensor, exponent Scalar) Tensor {
    f_pow(exponent)
}

func pow1(self Tensor, exponent Tensor) Tensor {
    f_pow1(exponent)
}

func pow2Scalar(self Tensor, self_scalar Scalar, exponent Tensor) Tensor {
    f_pow2(self_scalar, exponent)
}

func pow_Scalar(self Tensor, exponent Scalar) Tensor {
    f_pow_(exponent)
}

func pow_1(self Tensor, exponent Tensor) Tensor {
    f_pow_1(exponent)
}

func pow_outScalar(self Tensor, out Tensor, exponent Scalar) Tensor {
    f_pow_out(out, exponent)
}

func pow_out1(self Tensor, out Tensor, exponent Tensor) Tensor {
    f_pow_out1(out, exponent)
}

func pow_out2Scalar(self Tensor, out Tensor, self_scalar Scalar, exponent Tensor) Tensor {
    f_pow_out2(out, self_scalar, exponent)
}

func prelu(self Tensor, weight Tensor) Tensor {
    f_prelu(weight)
}

func prelu_backward(self Tensor, grad_output Tensor, weight Tensor) (Tensor, Tensor) {
    f_prelu_backward(grad_output, weight)
}

func prod(self Tensor, dtype Kind) Tensor {
    f_prod(dtype)
}

func prod1(self Tensor, dim int64, keepdim bool, dtype Kind) Tensor {
    f_prod1(dim, keepdim, dtype)
}

func prod_out(self Tensor, out Tensor, dim int64, keepdim bool, dtype Kind) Tensor {
    f_prod_out(out, dim, keepdim, dtype)
}

func put_(self Tensor, index Tensor, source Tensor, accumulate bool) Tensor {
    f_put_(index, source, accumulate)
}

func q_per_channel_scales(self Tensor, ) Tensor {
    f_q_per_channel_scales()
}

func q_per_channel_zero_points(self Tensor, ) Tensor {
    f_q_per_channel_zero_points()
}

func qr(self Tensor, some bool) (Tensor, Tensor) {
    f_qr(some)
}

func qr_out(self Tensor, q Tensor, r Tensor, some bool) (Tensor, Tensor) {
    f_qr_out(q, r, some)
}

func quantize_per_channel(self Tensor, scales Tensor, zero_points Tensor, axis int64, dtype Kind) Tensor {
    f_quantize_per_channel(scales, zero_points, axis, dtype)
}

func quantize_per_tensor(self Tensor, scale float64, zero_point int64, dtype Kind) Tensor {
    f_quantize_per_tensor(scale, zero_point, dtype)
}

func quantized_batch_normTensor(self Tensor, input Tensor, weight TensorOption, bias TensorOption, mean Tensor, var Tensor, eps float64, output_scale float64, output_zero_point int64) Tensor {
    f_quantized_batch_norm(input, weight, bias, mean, var, eps, output_scale, output_zero_point)
}

func quantized_gruTensor(self Tensor, input Tensor, hx Tensor, params []Tensor, has_biases bool, num_layers int64, dropout float64, train bool, bidirectional bool, batch_first bool) (Tensor, Tensor) {
    f_quantized_gru(input, hx, params, has_biases, num_layers, dropout, train, bidirectional, batch_first)
}

func quantized_gru1Tensor(self Tensor, data Tensor, batch_sizes Tensor, hx Tensor, params []Tensor, has_biases bool, num_layers int64, dropout float64, train bool, bidirectional bool) (Tensor, Tensor) {
    f_quantized_gru1(data, batch_sizes, hx, params, has_biases, num_layers, dropout, train, bidirectional)
}

func quantized_gru_cellScalar(self Tensor, input Tensor, hx Tensor, w_ih Tensor, w_hh Tensor, b_ih Tensor, b_hh Tensor, packed_ih Tensor, packed_hh Tensor, col_offsets_ih Tensor, col_offsets_hh Tensor, scale_ih Scalar, scale_hh Scalar, zero_point_ih Scalar, zero_point_hh Scalar) Tensor {
    f_quantized_gru_cell(input, hx, w_ih, w_hh, b_ih, b_hh, packed_ih, packed_hh, col_offsets_ih, col_offsets_hh, scale_ih, scale_hh, zero_point_ih, zero_point_hh)
}

func quantized_lstmTensor(self Tensor, input Tensor, hx []Tensor, params []Tensor, has_biases bool, num_layers int64, dropout float64, train bool, bidirectional bool, batch_first bool, dtype Kind, use_dynamic bool) (Tensor, Tensor, Tensor) {
    f_quantized_lstm(input, hx, params, has_biases, num_layers, dropout, train, bidirectional, batch_first, dtype, use_dynamic)
}

func quantized_lstm1Tensor(self Tensor, data Tensor, batch_sizes Tensor, hx []Tensor, params []Tensor, has_biases bool, num_layers int64, dropout float64, train bool, bidirectional bool, dtype Kind, use_dynamic bool) (Tensor, Tensor, Tensor) {
    f_quantized_lstm1(data, batch_sizes, hx, params, has_biases, num_layers, dropout, train, bidirectional, dtype, use_dynamic)
}

func quantized_lstm_cellTensor, Scalar(self Tensor, input Tensor, hx []Tensor, w_ih Tensor, w_hh Tensor, b_ih Tensor, b_hh Tensor, packed_ih Tensor, packed_hh Tensor, col_offsets_ih Tensor, col_offsets_hh Tensor, scale_ih Scalar, scale_hh Scalar, zero_point_ih Scalar, zero_point_hh Scalar) (Tensor, Tensor) {
    f_quantized_lstm_cell(input, hx, w_ih, w_hh, b_ih, b_hh, packed_ih, packed_hh, col_offsets_ih, col_offsets_hh, scale_ih, scale_hh, zero_point_ih, zero_point_hh)
}

func quantized_max_pool2d(self Tensor, kernel_size []int64, stride []int64, padding []int64, dilation []int64, ceil_mode bool) Tensor {
    f_quantized_max_pool2d(kernel_size, stride, padding, dilation, ceil_mode)
}

func quantized_rnn_relu_cellScalar(self Tensor, input Tensor, hx Tensor, w_ih Tensor, w_hh Tensor, b_ih Tensor, b_hh Tensor, packed_ih Tensor, packed_hh Tensor, col_offsets_ih Tensor, col_offsets_hh Tensor, scale_ih Scalar, scale_hh Scalar, zero_point_ih Scalar, zero_point_hh Scalar) Tensor {
    f_quantized_rnn_relu_cell(input, hx, w_ih, w_hh, b_ih, b_hh, packed_ih, packed_hh, col_offsets_ih, col_offsets_hh, scale_ih, scale_hh, zero_point_ih, zero_point_hh)
}

func quantized_rnn_tanh_cellScalar(self Tensor, input Tensor, hx Tensor, w_ih Tensor, w_hh Tensor, b_ih Tensor, b_hh Tensor, packed_ih Tensor, packed_hh Tensor, col_offsets_ih Tensor, col_offsets_hh Tensor, scale_ih Scalar, scale_hh Scalar, zero_point_ih Scalar, zero_point_hh Scalar) Tensor {
    f_quantized_rnn_tanh_cell(input, hx, w_ih, w_hh, b_ih, b_hh, packed_ih, packed_hh, col_offsets_ih, col_offsets_hh, scale_ih, scale_hh, zero_point_ih, zero_point_hh)
}

func rand(self Tensor, size []int64, options (Kind, Device)) Tensor {
    f_rand(size, options)
}

func rand_like(self Tensor, ) Tensor {
    f_rand_like()
}

func rand_out(self Tensor, out Tensor, size []int64) Tensor {
    f_rand_out(out, size)
}

func randint(self Tensor, high int64, size []int64, options (Kind, Device)) Tensor {
    f_randint(high, size, options)
}

func randint1(self Tensor, low int64, high int64, size []int64, options (Kind, Device)) Tensor {
    f_randint1(low, high, size, options)
}

func randint_like(self Tensor, high int64) Tensor {
    f_randint_like(high)
}

func randint_like1(self Tensor, low int64, high int64) Tensor {
    f_randint_like1(low, high)
}

func randint_out(self Tensor, out Tensor, high int64, size []int64) Tensor {
    f_randint_out(out, high, size)
}

func randint_out1(self Tensor, out Tensor, low int64, high int64, size []int64) Tensor {
    f_randint_out1(out, low, high, size)
}

func randn(self Tensor, size []int64, options (Kind, Device)) Tensor {
    f_randn(size, options)
}

func randn_like(self Tensor, ) Tensor {
    f_randn_like()
}

func randn_out(self Tensor, out Tensor, size []int64) Tensor {
    f_randn_out(out, size)
}

func random_(self Tensor, ) Tensor {
    f_random_()
}

func random_1(self Tensor, to int64) Tensor {
    f_random_1(to)
}

func random_2(self Tensor, from int64, to int64) Tensor {
    f_random_2(from, to)
}

func randperm(self Tensor, n int64, options (Kind, Device)) Tensor {
    f_randperm(n, options)
}

func randperm_out(self Tensor, out Tensor, n int64) Tensor {
    f_randperm_out(out, n)
}

func rangeScalar(self Tensor, start Scalar, end Scalar, options (Kind, Device)) Tensor {
    f_range(start, end, options)
}

func range1Scalar(self Tensor, start Scalar, end Scalar, options (Kind, Device)) Tensor {
    f_range1(start, end, options)
}

func range_outScalar(self Tensor, out Tensor, start Scalar, end Scalar) Tensor {
    f_range_out(out, start, end)
}

func real(self Tensor, ) Tensor {
    f_real()
}

func reciprocal(self Tensor, ) Tensor {
    f_reciprocal()
}

func reciprocal_(self Tensor, ) Tensor {
    f_reciprocal_()
}

func reciprocal_out(self Tensor, out Tensor) Tensor {
    f_reciprocal_out(out)
}

func reflection_pad1d(self Tensor, padding []int64) Tensor {
    f_reflection_pad1d(padding)
}

func reflection_pad1d_backward(self Tensor, grad_output Tensor, padding []int64) Tensor {
    f_reflection_pad1d_backward(grad_output, padding)
}

func reflection_pad1d_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, padding []int64) Tensor {
    f_reflection_pad1d_backward_out(grad_input, grad_output, padding)
}

func reflection_pad1d_out(self Tensor, out Tensor, padding []int64) Tensor {
    f_reflection_pad1d_out(out, padding)
}

func reflection_pad2d(self Tensor, padding []int64) Tensor {
    f_reflection_pad2d(padding)
}

func reflection_pad2d_backward(self Tensor, grad_output Tensor, padding []int64) Tensor {
    f_reflection_pad2d_backward(grad_output, padding)
}

func reflection_pad2d_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, padding []int64) Tensor {
    f_reflection_pad2d_backward_out(grad_input, grad_output, padding)
}

func reflection_pad2d_out(self Tensor, out Tensor, padding []int64) Tensor {
    f_reflection_pad2d_out(out, padding)
}

func relu(self Tensor, ) Tensor {
    f_relu()
}

func relu_(self Tensor, ) Tensor {
    f_relu_()
}

func remainderScalar(self Tensor, other Scalar) Tensor {
    f_remainder(other)
}

func remainder1(self Tensor, other Tensor) Tensor {
    f_remainder1(other)
}

func remainder_Scalar(self Tensor, other Scalar) Tensor {
    f_remainder_(other)
}

func remainder_1(self Tensor, other Tensor) Tensor {
    f_remainder_1(other)
}

func remainder_outScalar(self Tensor, out Tensor, other Scalar) Tensor {
    f_remainder_out(out, other)
}

func remainder_out1(self Tensor, out Tensor, other Tensor) Tensor {
    f_remainder_out1(out, other)
}

func renormScalar(self Tensor, p Scalar, dim int64, maxnorm Scalar) Tensor {
    f_renorm(p, dim, maxnorm)
}

func renorm_Scalar(self Tensor, p Scalar, dim int64, maxnorm Scalar) Tensor {
    f_renorm_(p, dim, maxnorm)
}

func renorm_outScalar(self Tensor, out Tensor, p Scalar, dim int64, maxnorm Scalar) Tensor {
    f_renorm_out(out, p, dim, maxnorm)
}

func repeat(self Tensor, repeats []int64) Tensor {
    f_repeat(repeats)
}

func repeat_interleave(self Tensor, repeats Tensor) Tensor {
    f_repeat_interleave(repeats)
}

func repeat_interleave1(self Tensor, repeats Tensor, dim int64) Tensor {
    f_repeat_interleave1(repeats, dim)
}

func repeat_interleave2(self Tensor, repeats int64, dim int64) Tensor {
    f_repeat_interleave2(repeats, dim)
}

func replication_pad1d(self Tensor, padding []int64) Tensor {
    f_replication_pad1d(padding)
}

func replication_pad1d_backward(self Tensor, grad_output Tensor, padding []int64) Tensor {
    f_replication_pad1d_backward(grad_output, padding)
}

func replication_pad1d_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, padding []int64) Tensor {
    f_replication_pad1d_backward_out(grad_input, grad_output, padding)
}

func replication_pad1d_out(self Tensor, out Tensor, padding []int64) Tensor {
    f_replication_pad1d_out(out, padding)
}

func replication_pad2d(self Tensor, padding []int64) Tensor {
    f_replication_pad2d(padding)
}

func replication_pad2d_backward(self Tensor, grad_output Tensor, padding []int64) Tensor {
    f_replication_pad2d_backward(grad_output, padding)
}

func replication_pad2d_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, padding []int64) Tensor {
    f_replication_pad2d_backward_out(grad_input, grad_output, padding)
}

func replication_pad2d_out(self Tensor, out Tensor, padding []int64) Tensor {
    f_replication_pad2d_out(out, padding)
}

func replication_pad3d(self Tensor, padding []int64) Tensor {
    f_replication_pad3d(padding)
}

func replication_pad3d_backward(self Tensor, grad_output Tensor, padding []int64) Tensor {
    f_replication_pad3d_backward(grad_output, padding)
}

func replication_pad3d_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, padding []int64) Tensor {
    f_replication_pad3d_backward_out(grad_input, grad_output, padding)
}

func replication_pad3d_out(self Tensor, out Tensor, padding []int64) Tensor {
    f_replication_pad3d_out(out, padding)
}

func requires_grad_(self Tensor, internal_requires_grad bool) Tensor {
    f_requires_grad_(internal_requires_grad)
}

func reshape(self Tensor, shape []int64) Tensor {
    f_reshape(shape)
}

func reshape_as(self Tensor, other Tensor) Tensor {
    f_reshape_as(other)
}

func resize_(self Tensor, size []int64) Tensor {
    f_resize_(size)
}

func resize_as_(self Tensor, the_template Tensor) Tensor {
    f_resize_as_(the_template)
}

func rfft(self Tensor, signal_ndim int64, normalized bool, onesided bool) Tensor {
    f_rfft(signal_ndim, normalized, onesided)
}

func rnn_reluTensor(self Tensor, input Tensor, hx Tensor, params []Tensor, has_biases bool, num_layers int64, dropout float64, train bool, bidirectional bool, batch_first bool) (Tensor, Tensor) {
    f_rnn_relu(input, hx, params, has_biases, num_layers, dropout, train, bidirectional, batch_first)
}

func rnn_relu1Tensor(self Tensor, data Tensor, batch_sizes Tensor, hx Tensor, params []Tensor, has_biases bool, num_layers int64, dropout float64, train bool, bidirectional bool) (Tensor, Tensor) {
    f_rnn_relu1(data, batch_sizes, hx, params, has_biases, num_layers, dropout, train, bidirectional)
}

func rnn_relu_cellTensor(self Tensor, input Tensor, hx Tensor, w_ih Tensor, w_hh Tensor, b_ih TensorOption, b_hh TensorOption) Tensor {
    f_rnn_relu_cell(input, hx, w_ih, w_hh, b_ih, b_hh)
}

func rnn_tanhTensor(self Tensor, input Tensor, hx Tensor, params []Tensor, has_biases bool, num_layers int64, dropout float64, train bool, bidirectional bool, batch_first bool) (Tensor, Tensor) {
    f_rnn_tanh(input, hx, params, has_biases, num_layers, dropout, train, bidirectional, batch_first)
}

func rnn_tanh1Tensor(self Tensor, data Tensor, batch_sizes Tensor, hx Tensor, params []Tensor, has_biases bool, num_layers int64, dropout float64, train bool, bidirectional bool) (Tensor, Tensor) {
    f_rnn_tanh1(data, batch_sizes, hx, params, has_biases, num_layers, dropout, train, bidirectional)
}

func rnn_tanh_cellTensor(self Tensor, input Tensor, hx Tensor, w_ih Tensor, w_hh Tensor, b_ih TensorOption, b_hh TensorOption) Tensor {
    f_rnn_tanh_cell(input, hx, w_ih, w_hh, b_ih, b_hh)
}

func roll(self Tensor, shifts []int64, dims []int64) Tensor {
    f_roll(shifts, dims)
}

func rot90(self Tensor, k int64, dims []int64) Tensor {
    f_rot90(k, dims)
}

func round(self Tensor, ) Tensor {
    f_round()
}

func round_(self Tensor, ) Tensor {
    f_round_()
}

func round_out(self Tensor, out Tensor) Tensor {
    f_round_out(out)
}

func rrelu(self Tensor, training bool) Tensor {
    f_rrelu(training)
}

func rrelu_(self Tensor, training bool) Tensor {
    f_rrelu_(training)
}

func rrelu_with_noise(self Tensor, noise Tensor, training bool) Tensor {
    f_rrelu_with_noise(noise, training)
}

func rrelu_with_noise_(self Tensor, noise Tensor, training bool) Tensor {
    f_rrelu_with_noise_(noise, training)
}

func rrelu_with_noise_backwardScalar(self Tensor, grad_output Tensor, noise Tensor, lower Scalar, upper Scalar, training bool, self_is_result bool) Tensor {
    f_rrelu_with_noise_backward(grad_output, noise, lower, upper, training, self_is_result)
}

func rrelu_with_noise_out(self Tensor, out Tensor, noise Tensor, training bool) Tensor {
    f_rrelu_with_noise_out(out, noise, training)
}

func rsqrt(self Tensor, ) Tensor {
    f_rsqrt()
}

func rsqrt_(self Tensor, ) Tensor {
    f_rsqrt_()
}

func rsqrt_out(self Tensor, out Tensor) Tensor {
    f_rsqrt_out(out)
}

func rsub(self Tensor, other Tensor) Tensor {
    f_rsub(other)
}

func rsub1Scalar(self Tensor, other Scalar) Tensor {
    f_rsub1(other)
}

func scalar_tensorScalar(self Tensor, s Scalar, options (Kind, Device)) Tensor {
    f_scalar_tensor(s, options)
}

func scatter(self Tensor, dim int64, index Tensor, src Tensor) Tensor {
    f_scatter(dim, index, src)
}

func scatter1Scalar(self Tensor, dim int64, index Tensor, value Scalar) Tensor {
    f_scatter1(dim, index, value)
}

func scatter_(self Tensor, dim int64, index Tensor, src Tensor) Tensor {
    f_scatter_(dim, index, src)
}

func scatter_1Scalar(self Tensor, dim int64, index Tensor, value Scalar) Tensor {
    f_scatter_1(dim, index, value)
}

func scatter_add(self Tensor, dim int64, index Tensor, src Tensor) Tensor {
    f_scatter_add(dim, index, src)
}

func scatter_add_(self Tensor, dim int64, index Tensor, src Tensor) Tensor {
    f_scatter_add_(dim, index, src)
}

func select(self Tensor, dim int64, index int64) Tensor {
    f_select(dim, index)
}

func selu(self Tensor, ) Tensor {
    f_selu()
}

func selu_(self Tensor, ) Tensor {
    f_selu_()
}

func set_(self Tensor, ) Tensor {
    f_set_()
}

func set_1(self Tensor, source Tensor) Tensor {
    f_set_1(source)
}

func set_requires_grad(self Tensor, r bool) Tensor {
    f_set_requires_grad(r)
}

func sigmoid(self Tensor, ) Tensor {
    f_sigmoid()
}

func sigmoid_(self Tensor, ) Tensor {
    f_sigmoid_()
}

func sigmoid_backward(self Tensor, grad_output Tensor, output Tensor) Tensor {
    f_sigmoid_backward(grad_output, output)
}

func sigmoid_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, output Tensor) Tensor {
    f_sigmoid_backward_out(grad_input, grad_output, output)
}

func sigmoid_out(self Tensor, out Tensor) Tensor {
    f_sigmoid_out(out)
}

func sign(self Tensor, ) Tensor {
    f_sign()
}

func sign_(self Tensor, ) Tensor {
    f_sign_()
}

func sign_out(self Tensor, out Tensor) Tensor {
    f_sign_out(out)
}

func sin(self Tensor, ) Tensor {
    f_sin()
}

func sin_(self Tensor, ) Tensor {
    f_sin_()
}

func sin_out(self Tensor, out Tensor) Tensor {
    f_sin_out(out)
}

func sinh(self Tensor, ) Tensor {
    f_sinh()
}

func sinh_(self Tensor, ) Tensor {
    f_sinh_()
}

func sinh_out(self Tensor, out Tensor) Tensor {
    f_sinh_out(out)
}

func slice(self Tensor, dim int64, start int64, end int64, step int64) Tensor {
    f_slice(dim, start, end, step)
}

func slogdet(self Tensor, ) (Tensor, Tensor) {
    f_slogdet()
}

func slow_conv3dTensor(self Tensor, weight Tensor, kernel_size []int64, bias TensorOption, stride []int64, padding []int64) Tensor {
    f_slow_conv3d(weight, kernel_size, bias, stride, padding)
}

func slow_conv3d_outTensor(self Tensor, out Tensor, weight Tensor, kernel_size []int64, bias TensorOption, stride []int64, padding []int64) Tensor {
    f_slow_conv3d_out(out, weight, kernel_size, bias, stride, padding)
}

func slow_conv_dilated2dTensor(self Tensor, weight Tensor, kernel_size []int64, bias TensorOption, stride []int64, padding []int64, dilation []int64) Tensor {
    f_slow_conv_dilated2d(weight, kernel_size, bias, stride, padding, dilation)
}

func slow_conv_dilated3dTensor(self Tensor, weight Tensor, kernel_size []int64, bias TensorOption, stride []int64, padding []int64, dilation []int64) Tensor {
    f_slow_conv_dilated3d(weight, kernel_size, bias, stride, padding, dilation)
}

func slow_conv_transpose2dTensor(self Tensor, weight Tensor, kernel_size []int64, bias TensorOption, stride []int64, padding []int64, output_padding []int64, dilation []int64) Tensor {
    f_slow_conv_transpose2d(weight, kernel_size, bias, stride, padding, output_padding, dilation)
}

func slow_conv_transpose2d_outTensor(self Tensor, out Tensor, weight Tensor, kernel_size []int64, bias TensorOption, stride []int64, padding []int64, output_padding []int64, dilation []int64) Tensor {
    f_slow_conv_transpose2d_out(out, weight, kernel_size, bias, stride, padding, output_padding, dilation)
}

func slow_conv_transpose3dTensor(self Tensor, weight Tensor, kernel_size []int64, bias TensorOption, stride []int64, padding []int64, output_padding []int64, dilation []int64) Tensor {
    f_slow_conv_transpose3d(weight, kernel_size, bias, stride, padding, output_padding, dilation)
}

func slow_conv_transpose3d_outTensor(self Tensor, out Tensor, weight Tensor, kernel_size []int64, bias TensorOption, stride []int64, padding []int64, output_padding []int64, dilation []int64) Tensor {
    f_slow_conv_transpose3d_out(out, weight, kernel_size, bias, stride, padding, output_padding, dilation)
}

func smm(self Tensor, mat2 Tensor) Tensor {
    f_smm(mat2)
}

func smooth_l1_loss(self Tensor, target Tensor, reduction int64) Tensor {
    f_smooth_l1_loss(target, reduction)
}

func smooth_l1_loss_backward(self Tensor, grad_output Tensor, target Tensor, reduction int64) Tensor {
    f_smooth_l1_loss_backward(grad_output, target, reduction)
}

func smooth_l1_loss_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, target Tensor, reduction int64) Tensor {
    f_smooth_l1_loss_backward_out(grad_input, grad_output, target, reduction)
}

func smooth_l1_loss_out(self Tensor, out Tensor, target Tensor, reduction int64) Tensor {
    f_smooth_l1_loss_out(out, target, reduction)
}

func soft_margin_loss(self Tensor, target Tensor, reduction int64) Tensor {
    f_soft_margin_loss(target, reduction)
}

func soft_margin_loss_backward(self Tensor, grad_output Tensor, target Tensor, reduction int64) Tensor {
    f_soft_margin_loss_backward(grad_output, target, reduction)
}

func soft_margin_loss_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, target Tensor, reduction int64) Tensor {
    f_soft_margin_loss_backward_out(grad_input, grad_output, target, reduction)
}

func soft_margin_loss_out(self Tensor, out Tensor, target Tensor, reduction int64) Tensor {
    f_soft_margin_loss_out(out, target, reduction)
}

func softmax(self Tensor, dim int64, dtype Kind) Tensor {
    f_softmax(dim, dtype)
}

func softplus(self Tensor, ) Tensor {
    f_softplus()
}

func softplus_backwardScalar(self Tensor, grad_output Tensor, beta Scalar, threshold Scalar, output Tensor) Tensor {
    f_softplus_backward(grad_output, beta, threshold, output)
}

func softplus_backward_outScalar(self Tensor, grad_input Tensor, grad_output Tensor, beta Scalar, threshold Scalar, output Tensor) Tensor {
    f_softplus_backward_out(grad_input, grad_output, beta, threshold, output)
}

func softplus_out(self Tensor, out Tensor) Tensor {
    f_softplus_out(out)
}

func softshrink(self Tensor, ) Tensor {
    f_softshrink()
}

func softshrink_backwardScalar(self Tensor, grad_output Tensor, lambd Scalar) Tensor {
    f_softshrink_backward(grad_output, lambd)
}

func softshrink_backward_outScalar(self Tensor, grad_input Tensor, grad_output Tensor, lambd Scalar) Tensor {
    f_softshrink_backward_out(grad_input, grad_output, lambd)
}

func softshrink_out(self Tensor, out Tensor) Tensor {
    f_softshrink_out(out)
}

func solve(self Tensor, a Tensor) (Tensor, Tensor) {
    f_solve(a)
}

func solve_out(self Tensor, solution Tensor, lu Tensor, a Tensor) (Tensor, Tensor) {
    f_solve_out(solution, lu, a)
}

func sort(self Tensor, dim int64, descending bool) (Tensor, Tensor) {
    f_sort(dim, descending)
}

func sort_out(self Tensor, values Tensor, indices Tensor, dim int64, descending bool) (Tensor, Tensor) {
    f_sort_out(values, indices, dim, descending)
}

func sparse_coo_tensor(self Tensor, size []int64, options (Kind, Device)) Tensor {
    f_sparse_coo_tensor(size, options)
}

func sparse_coo_tensor1(self Tensor, indices Tensor, values Tensor, options (Kind, Device)) Tensor {
    f_sparse_coo_tensor1(indices, values, options)
}

func sparse_coo_tensor2(self Tensor, indices Tensor, values Tensor, size []int64, options (Kind, Device)) Tensor {
    f_sparse_coo_tensor2(indices, values, size, options)
}

func sparse_mask(self Tensor, mask Tensor) Tensor {
    f_sparse_mask(mask)
}

func sparse_resize_(self Tensor, size []int64, sparse_dim int64, dense_dim int64) Tensor {
    f_sparse_resize_(size, sparse_dim, dense_dim)
}

func sparse_resize_and_clear_(self Tensor, size []int64, sparse_dim int64, dense_dim int64) Tensor {
    f_sparse_resize_and_clear_(size, sparse_dim, dense_dim)
}

func split(self Tensor, split_size int64, dim int64) []Tensor {
    f_split(split_size, dim)
}

func split_with_sizes(self Tensor, split_sizes []int64, dim int64) []Tensor {
    f_split_with_sizes(split_sizes, dim)
}

func sqrt(self Tensor, ) Tensor {
    f_sqrt()
}

func sqrt_(self Tensor, ) Tensor {
    f_sqrt_()
}

func sqrt_out(self Tensor, out Tensor) Tensor {
    f_sqrt_out(out)
}

func square(self Tensor, ) Tensor {
    f_square()
}

func square_(self Tensor, ) Tensor {
    f_square_()
}

func squeeze(self Tensor, ) Tensor {
    f_squeeze()
}

func squeeze1(self Tensor, dim int64) Tensor {
    f_squeeze1(dim)
}

func squeeze_(self Tensor, ) Tensor {
    f_squeeze_()
}

func squeeze_1(self Tensor, dim int64) Tensor {
    f_squeeze_1(dim)
}

func sspaddmm(self Tensor, mat1 Tensor, mat2 Tensor) Tensor {
    f_sspaddmm(mat1, mat2)
}

func sspaddmm_out(self Tensor, out Tensor, mat1 Tensor, mat2 Tensor) Tensor {
    f_sspaddmm_out(out, mat1, mat2)
}

func stackTensor(self Tensor, tensors []Tensor, dim int64) Tensor {
    f_stack(tensors, dim)
}

func stack_outTensor(self Tensor, out Tensor, tensors []Tensor, dim int64) Tensor {
    f_stack_out(out, tensors, dim)
}

func std(self Tensor, unbiased bool) Tensor {
    f_std(unbiased)
}

func std1(self Tensor, dim []int64, unbiased bool, keepdim bool) Tensor {
    f_std1(dim, unbiased, keepdim)
}

func std_mean(self Tensor, unbiased bool) (Tensor, Tensor) {
    f_std_mean(unbiased)
}

func std_mean1(self Tensor, dim []int64, unbiased bool, keepdim bool) (Tensor, Tensor) {
    f_std_mean1(dim, unbiased, keepdim)
}

func std_out(self Tensor, out Tensor, dim []int64, unbiased bool, keepdim bool) Tensor {
    f_std_out(out, dim, unbiased, keepdim)
}

func stftTensor(self Tensor, n_fft int64, hop_length int64, win_length int64, window TensorOption, normalized bool, onesided bool) Tensor {
    f_stft(n_fft, hop_length, win_length, window, normalized, onesided)
}

func g_sub(self Tensor, other Tensor) Tensor {
    f_sub(other)
}

func g_sub1Scalar(self Tensor, other Scalar) Tensor {
    f_sub1(other)
}

func g_sub_(self Tensor, other Tensor) Tensor {
    f_sub_(other)
}

func g_sub_1Scalar(self Tensor, other Scalar) Tensor {
    f_sub_1(other)
}

func sub_out(self Tensor, out Tensor, other Tensor) Tensor {
    f_sub_out(out, other)
}

func sum(self Tensor, dtype Kind) Tensor {
    f_sum(dtype)
}

func sum1(self Tensor, dim []int64, keepdim bool, dtype Kind) Tensor {
    f_sum1(dim, keepdim, dtype)
}

func sum_out(self Tensor, out Tensor, dim []int64, keepdim bool, dtype Kind) Tensor {
    f_sum_out(out, dim, keepdim, dtype)
}

func sum_to_size(self Tensor, size []int64) Tensor {
    f_sum_to_size(size)
}

func svd(self Tensor, some bool, compute_uv bool) (Tensor, Tensor, Tensor) {
    f_svd(some, compute_uv)
}

func svd_out(self Tensor, u Tensor, s Tensor, v Tensor, some bool, compute_uv bool) (Tensor, Tensor, Tensor) {
    f_svd_out(u, s, v, some, compute_uv)
}

func symeig(self Tensor, eigenvectors bool, upper bool) (Tensor, Tensor) {
    f_symeig(eigenvectors, upper)
}

func symeig_out(self Tensor, e Tensor, v Tensor, eigenvectors bool, upper bool) (Tensor, Tensor) {
    f_symeig_out(e, v, eigenvectors, upper)
}

func tr(self Tensor, ) Tensor {
    f_tr()
}

func t_(self Tensor, ) Tensor {
    f_t_()
}

func take(self Tensor, index Tensor) Tensor {
    f_take(index)
}

func take_out(self Tensor, out Tensor, index Tensor) Tensor {
    f_take_out(out, index)
}

func tan(self Tensor, ) Tensor {
    f_tan()
}

func tan_(self Tensor, ) Tensor {
    f_tan_()
}

func tan_out(self Tensor, out Tensor) Tensor {
    f_tan_out(out)
}

func tanh(self Tensor, ) Tensor {
    f_tanh()
}

func tanh_(self Tensor, ) Tensor {
    f_tanh_()
}

func tanh_backward(self Tensor, grad_output Tensor, output Tensor) Tensor {
    f_tanh_backward(grad_output, output)
}

func tanh_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, output Tensor) Tensor {
    f_tanh_backward_out(grad_input, grad_output, output)
}

func tanh_out(self Tensor, out Tensor) Tensor {
    f_tanh_out(out)
}

func tensordot(self Tensor, other Tensor, dims_self []int64, dims_other []int64) Tensor {
    f_tensordot(other, dims_self, dims_other)
}

func thresholdScalar(self Tensor, threshold Scalar, value Scalar) Tensor {
    f_threshold(threshold, value)
}

func threshold_Scalar(self Tensor, threshold Scalar, value Scalar) Tensor {
    f_threshold_(threshold, value)
}

func threshold_backwardScalar(self Tensor, grad_output Tensor, threshold Scalar) Tensor {
    f_threshold_backward(grad_output, threshold)
}

func threshold_outScalar(self Tensor, out Tensor, threshold Scalar, value Scalar) Tensor {
    f_threshold_out(out, threshold, value)
}

func to(self Tensor, device Device) Tensor {
    f_to(device)
}

func to1(self Tensor, options (Kind, Device), non_blocking bool, copy bool) Tensor {
    f_to1(options, non_blocking, copy)
}

func to2(self Tensor, dtype Kind, non_blocking bool, copy bool) Tensor {
    f_to2(dtype, non_blocking, copy)
}

func to3(self Tensor, other Tensor, non_blocking bool, copy bool) Tensor {
    f_to3(other, non_blocking, copy)
}

func to4(self Tensor, device Device, dtype Kind, non_blocking bool, copy bool) Tensor {
    f_to4(device, dtype, non_blocking, copy)
}

func to_dense(self Tensor, ) Tensor {
    f_to_dense()
}

func to_dense_backward(self Tensor, grad Tensor, input Tensor) Tensor {
    f_to_dense_backward(grad, input)
}

func to_mkldnn(self Tensor, ) Tensor {
    f_to_mkldnn()
}

func to_mkldnn_backward(self Tensor, grad Tensor, input Tensor) Tensor {
    f_to_mkldnn_backward(grad, input)
}

func to_sparse(self Tensor, ) Tensor {
    f_to_sparse()
}

func to_sparse1(self Tensor, sparse_dim int64) Tensor {
    f_to_sparse1(sparse_dim)
}

func topk(self Tensor, k int64, dim int64, largest bool, sorted bool) (Tensor, Tensor) {
    f_topk(k, dim, largest, sorted)
}

func topk_out(self Tensor, values Tensor, indices Tensor, k int64, dim int64, largest bool, sorted bool) (Tensor, Tensor) {
    f_topk_out(values, indices, k, dim, largest, sorted)
}

func totype(self Tensor, scalar_type Kind) Tensor {
    f_totype(scalar_type)
}

func trace(self Tensor, ) Tensor {
    f_trace()
}

func transpose(self Tensor, dim0 int64, dim1 int64) Tensor {
    f_transpose(dim0, dim1)
}

func transpose_(self Tensor, dim0 int64, dim1 int64) Tensor {
    f_transpose_(dim0, dim1)
}

func trapz(self Tensor, y Tensor, x Tensor, dim int64) Tensor {
    f_trapz(y, x, dim)
}

func trapz1(self Tensor, y Tensor, dx float64, dim int64) Tensor {
    f_trapz1(y, dx, dim)
}

func triangular_solve(self Tensor, a Tensor, upper bool, transpose bool, unitriangular bool) (Tensor, Tensor) {
    f_triangular_solve(a, upper, transpose, unitriangular)
}

func triangular_solve_out(self Tensor, x Tensor, m Tensor, a Tensor, upper bool, transpose bool, unitriangular bool) (Tensor, Tensor) {
    f_triangular_solve_out(x, m, a, upper, transpose, unitriangular)
}

func tril(self Tensor, diagonal int64) Tensor {
    f_tril(diagonal)
}

func tril_(self Tensor, diagonal int64) Tensor {
    f_tril_(diagonal)
}

func tril_indices(self Tensor, row int64, col int64, offset int64, options (Kind, Device)) Tensor {
    f_tril_indices(row, col, offset, options)
}

func tril_out(self Tensor, out Tensor, diagonal int64) Tensor {
    f_tril_out(out, diagonal)
}

func triplet_margin_loss(self Tensor, anchor Tensor, positive Tensor, negative Tensor, margin float64, p float64, eps float64, swap bool, reduction int64) Tensor {
    f_triplet_margin_loss(anchor, positive, negative, margin, p, eps, swap, reduction)
}

func triu(self Tensor, diagonal int64) Tensor {
    f_triu(diagonal)
}

func triu_(self Tensor, diagonal int64) Tensor {
    f_triu_(diagonal)
}

func triu_indices(self Tensor, row int64, col int64, offset int64, options (Kind, Device)) Tensor {
    f_triu_indices(row, col, offset, options)
}

func triu_out(self Tensor, out Tensor, diagonal int64) Tensor {
    f_triu_out(out, diagonal)
}

func true_divide(self Tensor, other Tensor) Tensor {
    f_true_divide(other)
}

func true_divide1Scalar(self Tensor, other Scalar) Tensor {
    f_true_divide1(other)
}

func true_divide_(self Tensor, other Tensor) Tensor {
    f_true_divide_(other)
}

func true_divide_1Scalar(self Tensor, other Scalar) Tensor {
    f_true_divide_1(other)
}

func true_divide_out(self Tensor, out Tensor, other Tensor) Tensor {
    f_true_divide_out(out, other)
}

func trunc(self Tensor, ) Tensor {
    f_trunc()
}

func trunc_(self Tensor, ) Tensor {
    f_trunc_()
}

func trunc_out(self Tensor, out Tensor) Tensor {
    f_trunc_out(out)
}

func type_as(self Tensor, other Tensor) Tensor {
    f_type_as(other)
}

func unbind(self Tensor, dim int64) []Tensor {
    f_unbind(dim)
}

func unfold(self Tensor, dimension int64, size int64, step int64) Tensor {
    f_unfold(dimension, size, step)
}

func uniform_(self Tensor, from float64, to float64) Tensor {
    f_uniform_(from, to)
}

func unique_consecutive(self Tensor, return_inverse bool, return_counts bool, dim int64) (Tensor, Tensor, Tensor) {
    f_unique_consecutive(return_inverse, return_counts, dim)
}

func unique_dim(self Tensor, dim int64, sorted bool, return_inverse bool, return_counts bool) (Tensor, Tensor, Tensor) {
    f_unique_dim(dim, sorted, return_inverse, return_counts)
}

func unique_dim_consecutive(self Tensor, dim int64, return_inverse bool, return_counts bool) (Tensor, Tensor, Tensor) {
    f_unique_dim_consecutive(dim, return_inverse, return_counts)
}

func unsqueeze(self Tensor, dim int64) Tensor {
    f_unsqueeze(dim)
}

func unsqueeze_(self Tensor, dim int64) Tensor {
    f_unsqueeze_(dim)
}

func upsample_bicubic2d(self Tensor, output_size []int64, align_corners bool, scales_h float64, scales_w float64) Tensor {
    f_upsample_bicubic2d(output_size, align_corners, scales_h, scales_w)
}

func upsample_bicubic2d_backward(self Tensor, grad_output Tensor, output_size []int64, input_size []int64, align_corners bool, scales_h float64, scales_w float64) Tensor {
    f_upsample_bicubic2d_backward(grad_output, output_size, input_size, align_corners, scales_h, scales_w)
}

func upsample_bicubic2d_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, output_size []int64, input_size []int64, align_corners bool, scales_h float64, scales_w float64) Tensor {
    f_upsample_bicubic2d_backward_out(grad_input, grad_output, output_size, input_size, align_corners, scales_h, scales_w)
}

func upsample_bicubic2d_out(self Tensor, out Tensor, output_size []int64, align_corners bool, scales_h float64, scales_w float64) Tensor {
    f_upsample_bicubic2d_out(out, output_size, align_corners, scales_h, scales_w)
}

func upsample_bilinear2d(self Tensor, output_size []int64, align_corners bool, scales_h float64, scales_w float64) Tensor {
    f_upsample_bilinear2d(output_size, align_corners, scales_h, scales_w)
}

func upsample_bilinear2d_backward(self Tensor, grad_output Tensor, output_size []int64, input_size []int64, align_corners bool, scales_h float64, scales_w float64) Tensor {
    f_upsample_bilinear2d_backward(grad_output, output_size, input_size, align_corners, scales_h, scales_w)
}

func upsample_bilinear2d_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, output_size []int64, input_size []int64, align_corners bool, scales_h float64, scales_w float64) Tensor {
    f_upsample_bilinear2d_backward_out(grad_input, grad_output, output_size, input_size, align_corners, scales_h, scales_w)
}

func upsample_bilinear2d_out(self Tensor, out Tensor, output_size []int64, align_corners bool, scales_h float64, scales_w float64) Tensor {
    f_upsample_bilinear2d_out(out, output_size, align_corners, scales_h, scales_w)
}

func upsample_linear1d(self Tensor, output_size []int64, align_corners bool, scales float64) Tensor {
    f_upsample_linear1d(output_size, align_corners, scales)
}

func upsample_linear1d_backward(self Tensor, grad_output Tensor, output_size []int64, input_size []int64, align_corners bool, scales float64) Tensor {
    f_upsample_linear1d_backward(grad_output, output_size, input_size, align_corners, scales)
}

func upsample_linear1d_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, output_size []int64, input_size []int64, align_corners bool, scales float64) Tensor {
    f_upsample_linear1d_backward_out(grad_input, grad_output, output_size, input_size, align_corners, scales)
}

func upsample_linear1d_out(self Tensor, out Tensor, output_size []int64, align_corners bool, scales float64) Tensor {
    f_upsample_linear1d_out(out, output_size, align_corners, scales)
}

func upsample_nearest1d(self Tensor, output_size []int64, scales float64) Tensor {
    f_upsample_nearest1d(output_size, scales)
}

func upsample_nearest1d_backward(self Tensor, grad_output Tensor, output_size []int64, input_size []int64, scales float64) Tensor {
    f_upsample_nearest1d_backward(grad_output, output_size, input_size, scales)
}

func upsample_nearest1d_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, output_size []int64, input_size []int64, scales float64) Tensor {
    f_upsample_nearest1d_backward_out(grad_input, grad_output, output_size, input_size, scales)
}

func upsample_nearest1d_out(self Tensor, out Tensor, output_size []int64, scales float64) Tensor {
    f_upsample_nearest1d_out(out, output_size, scales)
}

func upsample_nearest2d(self Tensor, output_size []int64, scales_h float64, scales_w float64) Tensor {
    f_upsample_nearest2d(output_size, scales_h, scales_w)
}

func upsample_nearest2d_backward(self Tensor, grad_output Tensor, output_size []int64, input_size []int64, scales_h float64, scales_w float64) Tensor {
    f_upsample_nearest2d_backward(grad_output, output_size, input_size, scales_h, scales_w)
}

func upsample_nearest2d_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, output_size []int64, input_size []int64, scales_h float64, scales_w float64) Tensor {
    f_upsample_nearest2d_backward_out(grad_input, grad_output, output_size, input_size, scales_h, scales_w)
}

func upsample_nearest2d_out(self Tensor, out Tensor, output_size []int64, scales_h float64, scales_w float64) Tensor {
    f_upsample_nearest2d_out(out, output_size, scales_h, scales_w)
}

func upsample_nearest3d(self Tensor, output_size []int64, scales_d float64, scales_h float64, scales_w float64) Tensor {
    f_upsample_nearest3d(output_size, scales_d, scales_h, scales_w)
}

func upsample_nearest3d_backward(self Tensor, grad_output Tensor, output_size []int64, input_size []int64, scales_d float64, scales_h float64, scales_w float64) Tensor {
    f_upsample_nearest3d_backward(grad_output, output_size, input_size, scales_d, scales_h, scales_w)
}

func upsample_nearest3d_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, output_size []int64, input_size []int64, scales_d float64, scales_h float64, scales_w float64) Tensor {
    f_upsample_nearest3d_backward_out(grad_input, grad_output, output_size, input_size, scales_d, scales_h, scales_w)
}

func upsample_nearest3d_out(self Tensor, out Tensor, output_size []int64, scales_d float64, scales_h float64, scales_w float64) Tensor {
    f_upsample_nearest3d_out(out, output_size, scales_d, scales_h, scales_w)
}

func upsample_trilinear3d(self Tensor, output_size []int64, align_corners bool, scales_d float64, scales_h float64, scales_w float64) Tensor {
    f_upsample_trilinear3d(output_size, align_corners, scales_d, scales_h, scales_w)
}

func upsample_trilinear3d_backward(self Tensor, grad_output Tensor, output_size []int64, input_size []int64, align_corners bool, scales_d float64, scales_h float64, scales_w float64) Tensor {
    f_upsample_trilinear3d_backward(grad_output, output_size, input_size, align_corners, scales_d, scales_h, scales_w)
}

func upsample_trilinear3d_backward_out(self Tensor, grad_input Tensor, grad_output Tensor, output_size []int64, input_size []int64, align_corners bool, scales_d float64, scales_h float64, scales_w float64) Tensor {
    f_upsample_trilinear3d_backward_out(grad_input, grad_output, output_size, input_size, align_corners, scales_d, scales_h, scales_w)
}

func upsample_trilinear3d_out(self Tensor, out Tensor, output_size []int64, align_corners bool, scales_d float64, scales_h float64, scales_w float64) Tensor {
    f_upsample_trilinear3d_out(out, output_size, align_corners, scales_d, scales_h, scales_w)
}

func values(self Tensor, ) Tensor {
    f_values()
}

func var(self Tensor, unbiased bool) Tensor {
    f_var(unbiased)
}

func var1(self Tensor, dim []int64, unbiased bool, keepdim bool) Tensor {
    f_var1(dim, unbiased, keepdim)
}

func var_mean(self Tensor, unbiased bool) (Tensor, Tensor) {
    f_var_mean(unbiased)
}

func var_mean1(self Tensor, dim []int64, unbiased bool, keepdim bool) (Tensor, Tensor) {
    f_var_mean1(dim, unbiased, keepdim)
}

func var_out(self Tensor, out Tensor, dim []int64, unbiased bool, keepdim bool) Tensor {
    f_var_out(out, dim, unbiased, keepdim)
}

func view_(self Tensor, size []int64) Tensor {
    f_view_(size)
}

func view_as(self Tensor, other Tensor) Tensor {
    f_view_as(other)
}

func where_(self Tensor, condition Tensor) []Tensor {
    f_where_(condition)
}

func where1(self Tensor, condition Tensor, other Tensor) Tensor {
    f_where1(condition, other)
}

func zero_(self Tensor, ) Tensor {
    f_zero_()
}

func zeros(self Tensor, size []int64, options (Kind, Device)) Tensor {
    f_zeros(size, options)
}

func zeros_like(self Tensor, ) Tensor {
    f_zeros_like()
}

func zeros_out(self Tensor, out Tensor, size []int64) Tensor {
    f_zeros_out(out, size)
}
// End of implementing Tensor ================================= 
